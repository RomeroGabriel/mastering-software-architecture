{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Mastering Software Architecture","text":"<p>An one-stop Wiki for Software Architecture studies. A centralized repository for all things architecture! \ud83c\udfdb\ufe0f #SoftwareArchitectures</p>"},{"location":"#references","title":"References","text":"<p>The following is a list of materials utilized for studying and creating this documentation:</p> <ul> <li>Fundamentals of Software Architecture</li> </ul> <p>*and of course chatGPT </p>"},{"location":"arch_characteristics/arch_characteristics/","title":"Architecture Characteristics","text":"<p>Architects must account for numerous factors when designing a software solution, including:</p> <ol> <li>Auditability;</li> <li>Performance;</li> <li>Security;</li> <li>Requirements;</li> <li>Data;</li> <li>Legality;</li> <li>Scalability;</li> </ol> <p>In software architecture, architects may collaborate on defining domain or business requirements. However, a <code>key responsibility involves identifying, discovering, and analyzing all the tasks that the software must perform beyond the domain functionality</code> \u2013 these are known as architectural characteristics. Architectural characteristics are sometimes referred to as <code>nonfunctional requirements</code>.</p> <p>Architecture characteristics can be divided into <code>implicit</code> and <code>explicit</code> types. Implicit characteristics, such as <code>availability, reliability, and security</code>, often <code>don't explicitly appear in requirements but are crucial</code> for project success. Architects must leverage their <code>domain knowledge</code> to unveil these characteristics during the analysis phase. For instance, a high-frequency trading firm might not explicitly mention low latency, but architects familiar with that domain understand its critical significance.</p> <p>An architectural characteristic meets three criteria:</p> <ol> <li>It specifies a design consideration unrelated to the domain.</li> <li>It impacts a structural aspect of the design.</li> <li>It is crucial or significantly contributes to the success of the application.</li> </ol>"},{"location":"arch_characteristics/arch_characteristics/#criteria-for-architectural-characteristics","title":"Criteria for Architectural Characteristics","text":""},{"location":"arch_characteristics/arch_characteristics/#specifies-a-nondomain-design-consideration","title":"Specifies a Nondomain Design Consideration","text":"<p>Architecture characteristics <code>define criteria for the successful operation and design of a system</code>. They outline <code>how requirements will be implemented and justify design choices</code>. For example, one common and significant architectural characteristic involves defining a specific performance level for the application. Often, this level of performance <code>isn't explicitly stated in the initial requirements document</code>.</p>"},{"location":"arch_characteristics/arch_characteristics/#influences-some-structural-aspect-of-the-design","title":"Influences Some Structural Aspect of the Design","text":"<p>Architects primarily focus on <code>describing architectural characteristics in projects</code> to address design considerations: <code>does a specific characteristic demand distinct structural attention for its success?</code> Take security, for instance - while it's a concern in nearly every project, basic precautions are usually integrated during design and coding. However, it becomes an architectural characteristic when the architect must devise something unique to address it, for example integrate an external payment processor.</p>"},{"location":"arch_characteristics/arch_characteristics/#is-critical-or-important-to-application-success","title":"Is critical or important to application success","text":"<p>Applications have the potential to accommodate numerous architectural characteristics, but this should be approached with caution. <code>Each added characteristic introduces complexity to the design</code>. Therefore, a vital task for architects is to focus on <code>selecting a minimal set of architecture characteristics rather than striving for the maximum possible</code>.</p>"},{"location":"arch_characteristics/arch_characteristics/#architectural-characteristics-partially-listed","title":"Architectural Characteristics (Partially) Listed","text":"<p>Architecture characteristics span from low-level code attributes to sophisticated operational concerns, such as scalability and elasticity. Additionally, as the software ecosystem evolves rapidly, new concepts, tools, and terms emerge, introducing novel characteristics. Operational architecture characteristics often <code>closely align with operations and DevOps considerations</code>, representing a significant intersection of these concerns within numerous software projects.</p>"},{"location":"arch_characteristics/arch_characteristics/#operational-architecture-characteristics","title":"Operational Architecture Characteristics","text":"<p>Operational architecture characteristics encompass capabilities such as performance, scalability, elasticity, availability, and reliability.</p> Tern Definition Availability How long the system will need to be available. Continuity Disaster recovery capability. <code>Performance</code> Involves stress testing, peak analysis, frequency of function usage, response times, etc. Can demand a dedicated effort and time. Recoverability Ensuring business continuity during disasters: How swiftly can recovery be achieved? This influences backup strategies and hardware redundancy needs. <code>Reliability/safety</code> Assess if the system needs to be fail-safe, or if it is mission critical in a way that affects lives. If it fails, what's happen? Robustness Ability to handle error and boundary conditions while running. <code>Scalability</code> Ability for the system to perform and operate as the number of users or requests increases."},{"location":"arch_characteristics/arch_characteristics/#structural-architecture-characteristics","title":"Structural Architecture Characteristics","text":"<p>These characteristics focus on code structure. Architects often bear the responsibility for code quality, including modularity, controlled component coupling, readability, and various internal quality evaluations.</p> Tern Definition <code>Configurability</code> Ability for the end users to easily change aspects of the software\u2019s configuration (through usable interfaces). <code>Extensibility</code> How important it is to plug new pieces of functionality in. <code>Installability</code> Ease of system installation on all necessary platforms. <code>Leverageability/reuse</code> Ability to leverage common components across multiple products. Localization Support for multiple languages. <code>Maintainability</code> How easy it is to apply changes and enhance the system? <code>Portability</code> Platforms that the system must support. Upgradeability Ability to easily/quickly upgrade from a previous version."},{"location":"arch_characteristics/arch_characteristics/#cross-cutting-architecture-characteristics","title":"Cross-Cutting Architecture Characteristics","text":"<p>Architecture characteristics that lack a definitive categorization yet form important design constraints and considerations.</p> Tern Definition Accessibility Access to all your users, including those with disabilities like colorblindness or hearing loss. Archivability Will the data need to be archived or deleted after a period of time? (For example, delete a user after three months inactive) <code>Authentication</code> Security requirements to ensure users are who they say they are. <code>Authorization</code> Security requirements to ensure users can access only certain functions within the application. Legal What legislative constraints is the system operating in. Privacy Ability to hide transactions from internal company employees (encrypted transactions so even DBAs and network architects cannot see them). <code>Security</code> Does the data need to be encrypted in the database? Encrypted for network communication between internal systems? What type of authentication needs to be in place for remote user access? <code>Supportability</code> What level of technical support is needed by the application? What level of logging and other facilities are required to debug errors in the system? Usability/achievability Level of training required for users to achieve their goals."},{"location":"arch_characteristics/arch_characteristics/#iso-architecture-characteristics-list","title":"ISO Architecture Characteristics List","text":"<p>It's basically impossible to list all characteristics, and many of the definitions overlap. The ISO's list describes some other characteristics as well.</p>"},{"location":"arch_characteristics/arch_characteristics/#trade-offs-and-define-architecture","title":"Trade-Offs and Define Architecture","text":"<p>Applications <code>can only support a subset</code> of the architecture characteristics due to various reasons. First, each supported characteristic <code>requires design effort and possibly structural support</code>. Second, a significant challenge arises from the fact that <code>each architecture characteristic often impacts others</code>, as seen in the example of security versus performance. Hence, architects rarely find themselves in a situation where they can design a system that maximizes every single architecture characteristic.</p> <p>Architects <code>should aim to design architecture that is as iterative as possible</code>. By enabling easier changes to the architecture, there's <code>less pressure to discover the exact correct solution</code> in the initial attempt. One of the crucial lessons from Agile software development is the value of iteration, which holds true across all levels of software development, including architecture.</p>"},{"location":"arch_characteristics/arch_characteristics/#references","title":"References","text":"<ul> <li>Fundamentals of Software Architecture</li> </ul>"},{"location":"arch_characteristics/identifying_characteristics/","title":"Identifying Architectural Characteristics","text":"<p>It's really important identifying architectural characteristics to <code>start creating or checking an existing architecture</code>. To figure out the right architectural stuff, an architect needs to <code>understand the domain problem well</code>. Also, working together with domain stakeholders is crucial to <code>decide what really matters</code>.</p> <p>To find the architectural features in a project, there are at least three ways: you can get them from <code>domain concerns, project requirements, and and implicit domain knowledge</code>.</p>"},{"location":"arch_characteristics/identifying_characteristics/#extracting-architecture-characteristics-from-domain-concerns","title":"Extracting Architecture Characteristics from Domain Concerns","text":"<p>An architect must be able to <code>translate domain concerns to identify the right architectural characteristics</code>. By <code>understanding the key domain goals and domain situation</code>, the architect can <code>turn those worries into features</code>. These features then guide the smart choices for the architecture.</p> <p>One tip is when working with the domain stakeholders to decide the important architecture features, <code>try to keep the list of architectural characteristics short</code>. <code>Every feature added makes the design more complex and that's risky</code>. Don't get caught up in the number of features, but rather <code>focus on keeping the design simple</code>.</p>"},{"location":"arch_characteristics/identifying_characteristics/#architects-vs-stakeholders","title":"Architects vs Stakeholders","text":"<p>When architects and stakeholders are figuring out which architecture characteristics to focus on, it's a good idea to <code>let domain stakeholders choose the top three most important ones</code>. This <code>helps avoid problems since not everyone agrees</code> on the priority of each characteristic. This way, it's easier to <code>find common ground and helps the architect analyze trade-offs when making vital architecture decisions</code>.</p> <p>Most of the time, <code>architecture characteristics come from talking to key domain stakeholders and working together to figure out what matters</code>. The challenge is that architects and domain stakeholders use different terms. Architects talk about things like scalability and interoperability, while domain stakeholders talk about stuff like user happiness and getting things done quickly. The table below helps translate from domain concerns to architecture characteristics.</p> Domain concern Architecture characteristics Mergers and acquisitions Interoperability, scalability, adaptability, extensibility Time to market Agility, testability, deployability User satisfaction Performance, availability, fault tolerance, testability, deployability, agility, security Competitive advantage Agility, testability, deployability, scalability, availability, fault tolerance Time and budget Simplicity, feasibility <p>Translate from domain concerns to architecture characteristics from Fundamentals of Software Architecture.</p> <p>However, it's important to note that <code>this translation isn't a strict rule to blindly follow</code>. This is a common pitfall that many architects encounter when translating domain concerns. Being agile doesn't always mean getting to the market quickly. Time to market is a mix of agility, testability, and deployability. <code>Concentrating solely on one characteristic can lead to issues when trying to achieve goals</code>. For instance, focusing solely on performance when delivering a feature might cause availability problems when needed. And if the domain grows, will the system be able to scale?</p>"},{"location":"arch_characteristics/identifying_characteristics/#extracting-architecture-characteristics-from-requirements","title":"Extracting Architecture Characteristics from Requirements","text":"<p>Certain architecture characteristics are <code>derived from clear statements in requirements documents</code>, such as the expected number of users or peak usage times for the application. Others are <code>based on the inherent domain knowledge possessed by architects</code>. For example, an architect experienced in finance systems knows when and where to scale the software artifacts effectively.</p>"},{"location":"arch_characteristics/identifying_characteristics/#references","title":"References","text":"<ul> <li>Fundamentals of Software Architecture</li> </ul>"},{"location":"arch_characteristics/measuring_governing/","title":"Measuring and Governing Architecture Characteristics","text":""},{"location":"arch_characteristics/measuring_governing/#measuring-architecture-characteristics","title":"Measuring Architecture Characteristics","text":"<p>Organizations often encounter various <code>common challenges when defining architecture characteristics</code>:</p> <ol> <li> They aren\u2019t physics Numerous commonly used <code>architecture characteristics have unclear definitions</code>. For instance, what exactly does it mean for an architect to design for agility or deployability? </li> <li> Wildly varying definitions Even within the same organization, it can be challenging to establish a shared understanding of features like performance. </li> <li> Too composite Many important <code>architecture characteristics actually consist of several smaller components.</code> For example, when we talk about agility, it involves things like modularity, deployability, and testability that contribute to it. </li> </ol> <p><code>Having clear and precise definitions for architecture characteristics</code> addresses these issues effectively. When an organization universally agrees on concrete definitions for these characteristics, it <code>establishes a shared language for discussing architecture</code>. Furthermore, by promoting objective definitions, teams can break down complex characteristics into specific, measurable features that they can define objectively.</p>"},{"location":"arch_characteristics/measuring_governing/#operational-measures","title":"Operational Measures","text":"<p>Numerous measurements have <code>nuanced interpretations depending on their specific goals</code>. Take, for instance, <code>measuring performance through the average response time for certain requests</code> \u2013 a prime example of operational architecture characteristics measurement. However, if teams solely focus on the average, they might <code>miss outliers caused by specific boundary conditions</code>, where 1% of requests take significantly longer than others. Hence, teams may also find it valuable to measure maximum response times to capture these outliers.</p> The variety of performance <p>Keep performance as example, architects and DevOps engineers have put in significant effort to <code>create performance budgets</code>, which are precise limits for various aspects of the application. For instance, an <code>ideal first-page render time</code> is set at 500 milliseconds\u2014half a second.</p> <p>Some of these metrics also carry <code>further implications for application design</code>. Forward-looking organizations often set size-based budgets for page downloads: a maximum limit for the amount of bytes allocated to libraries and frameworks on a given page.</p> <p>Top-tier teams don't just pick performance numbers out of thin air. <code>They use stats</code>. For example, say a video streaming service wants to monitor scalability. <code>Rather than set an arbitrary number as the goal, eengineers measure scalability over time, create statistical models, and sound alarms if real-time stats diverge from predictions.</code> A failure implies either a flawed model (good to know) or a problem (also good to know).</p>"},{"location":"arch_characteristics/measuring_governing/#structural-measures","title":"Structural Measures","text":"<p>Structural measures, unlike performance, <code>deal with code quality</code>, and unfortunately, we <code>don't have comprehensive metrics for internal code quality yet</code>. Nevertheless, there are some metrics and common tools that architects can use to address important aspects of code structure.</p> Cyclomatic Complexity Metric <p>Cyclomatic Complexity (CC) is a <code>code-level metric</code>. It offers a <code>quantifiable way to assess code complexity</code>, whether it's at the function/method, class, or application level.</p> <p>It is computed by <code>applying graph theory to code, specifically decision points, which cause different execution paths</code>. For example, if a function has no decision statements (such as if statements), then CC = 1. If the function had a single conditional, then CC = 2 because two possible execution paths exist.</p> <p>Architects and developers universally recognize that <code>excessively complex code is a code smell</code>. It undermines almost all the positive traits of codebases, like modularity, testability, deployability, and more. However, if teams <code>neglect monitoring the gradual increase in complexity, it can eventually overpower the entire codebase</code>.</p>"},{"location":"arch_characteristics/measuring_governing/#process-measures","title":"Process Measures","text":"<p>Certain <code>architecture characteristics align with software development processes</code>. Agility, for instance, is frequently seen as a valuable trait. Nevertheless, <code>it's a composite architecture characteristic that architects may break down into features like testability and deployability</code>.</p> Testability <p><code>Testability can be quantified using code coverage tools in testing</code>. However, it's essential to note that, like all software checks, <code>it cannot substitute critical thinking and intention</code>. For instance, a codebase might achieve 100% code coverage but still have weak assertions that don't genuinely ensure code correctness. Nonetheless, <code>testability is clearly an objectively measurable characteristic</code>.</p> Deployability <p>Teams can measure deployability via a variety of metricslike the success-to-failure deployment ratio, deployment duration, and more. <code>Teams need to determine suitable measurements that provide valuable data for their organization, focusing on quality and quantity</code>. These measurements often align with team priorities and objectives.</p> <p><code>Agility and its related aspects are closely tied to the software development process</code>. However, this process <code>can also influence the architecture's structure</code>. For instance, <code>if easy deployment and testability are high priorities, architects may focus more on robust modularity and isolation in the architecture</code> \u2013 an example of an architecture characteristic influencing a structural choice.</p>"},{"location":"arch_characteristics/measuring_governing/#governance-and-fitness-functions","title":"Governance and Fitness Functions","text":"<p>After architects define and prioritize architecture characteristics, <code>how can they ensure that developers prioritize those too?</code> In many software projects, urgency dominates, yet architects still require a governance mechanism.</p> <p><code>Architecture governance encompasses all aspects of the software development process that architects aim to influence</code>, such as maintaining software quality within an organization.</p> <p>There are increasingly advanced solutions available to help architects address this challenge. The book Building Evolutionary Architectures introduces a set of <code>techniques known as fitness functions, which can automate various aspects of this process.</code></p>"},{"location":"arch_characteristics/measuring_governing/#fitness-functions","title":"Fitness Functions","text":"<p>A fitness function is a <code>guidance mechanism</code>. It's a way to measure how closely the <code>output of an objective function aligns with achieving a specific goal</code>. For instance, when evaluating an algorithm that tackles the traveling salesperson problem, <code>one fitness function might check how long the route is and aim for the shortest one</code>. Another could look at <code>how much it costs and try to keep that cost low</code>. Yet another might consider how much time the salesperson is away and try to make the travel time shorter.</p> <p><code>Architecture fitness functions refer to any method that offers an objective evaluation of an architecture characteristic or a combination of them</code>. These functions encompass various verification methods, depending on their application: metrics, monitors, unit testing libraries, chaos engineering, and more.</p> <p>For more information and examples, Fitness function-driven development</p>"},{"location":"arch_characteristics/measuring_governing/#references","title":"References","text":"<ul> <li>Fundamentals of Software Architecture</li> </ul>"},{"location":"arch_characteristics/scope/","title":"Scope of Architecture Characteristics","text":"<p>In the past, within the realm of software architecture, <code>the scope of architecture characteristics was traditionally placed at the system level</code>. For instance, scalability was discussed with the entire system in mind, as most systems were monolithic. However, <code>this is no longer accurate today</code>, as the field has evolved, exemplified by the emergence of microservices.</p> <p>There are various <code>code-level metrics</code> that enable architects to analyze the structural aspects of an architecture. However, these metrics often offer insights into low-level code specifics, <code>rather than the entirety of a system's components</code>. For example, databases can significantly influence various architecture characteristics, particularly operational ones. Code performance won't matter if the database doesn't scale.</p> <p>Architects must also consider <code>external components beyond the codebase that can influence these characteristics</code>. Furthermore, it's crucial to measure these types of dependencies.</p>"},{"location":"arch_characteristics/scope/#architectural-quanta-and-granularity","title":"Architectural Quanta and Granularity","text":"<p>To define the architecture quantum, we needed a measure of how components are \u201cwired\u201d together, which corresponds to the connascence concept. Connascence map dependencies between components, classifying them between static connascence or dynamic connascence.</p> <p>The definition about architecture quantum is:</p> <p>An independently deployable artifact with high functional cohesion and synchronous connascence</p> Independently deployable <p>An architectural quantum is a <code>self-sufficient unit that includes everything needed to work on its own within the larger architecture</code>. For instance, if an application relies on a database, the database is considered part of this self-contained unit because the application can't function without it..</p> High functional cohesion <p>Functional cohesion in component design <code>measures how well the code within a component serves a single, meaningful purpose</code>. In microservices architectures, high functional cohesion is particularly important because each service is typically designed to handle a specific workflow or function, ensuring clarity and efficiency in the system's organization.</p> Synchronous connascence <p>Synchronous connascence <code>refers to synchronous calls within an application context or between distributed services within an architecture quantum</code>. In a microservices architecture, when one service calls another synchronously, it's crucial that both services have similar operational architecture characteristics. If there's a significant difference in scalability between the caller and callee, issues like timeouts and reliability problems may arise.</p> <p>The concept of <code>architecture quantum provides the new scope for architecture characteristics</code>. In modern systems, <code>architects define these characteristics at the quantum level/specific parts</code>, rather than at the system level/whole system.  By <code>focusing on a more specific scope for essential operational concerns, architects can detect architectural challenges early</code>, which can lead to the development of hybrid architectures.</p>"},{"location":"arch_characteristics/scope/#choosing-between-monolithic-x-distributed-architectures","title":"Choosing Between Monolithic x Distributed Architectures","text":"<p>The choice between a monolithic and distributed architecture <code>depends on the scope of architecture characteristics</code>. A monolithic architecture consists of a single deployable unit that contains all system functionality and is typically connected to a single database. In contrast, a distributed architecture involves multiple services running independently, communicating through networking protocols.</p> <p>The decision hinges on how many architecture quanta are discovered during the design process. <code>If the system can function effectively with a single quantum (meaning one set of architecture characteristics), a monolithic architecture is advantageous</code>. However, <code>if different components require distinct architecture characteristics, a distributed architecture</code> is necessary to accommodate these variations.</p> <p>The ability to make this fundamental architectural decision early in the design process underscores the benefits of using the architecture quantum to analyze architecture characteristics' scope and coupling.</p>"},{"location":"arch_characteristics/scope/#references","title":"References","text":"<ul> <li>Fundamentals of Software Architecture</li> </ul>"},{"location":"arch_decisions/","title":"Architecture Decisions","text":"<p>Architects play a pivotal role in making crucial architecture decisions that shape the application or system. <code>While these decisions primarily influence the structure of the application or system, they might also extend to technology choices, especially when they impact essential architectural characteristics</code>. Regardless of the context, a good architecture decision serves as a guiding force for development teams, helping them in making in making the right technical choices. The process involves <code>gathering relevant information, providing clear justifications, documenting decisions, and ensuring effective communication with the pertinent stakeholders</code>.</p>"},{"location":"arch_decisions/#architecture-decision-anti-patterns","title":"Architecture Decision Anti-Patterns","text":"<p>Not surprisingly, <code>several pitfalls emerge when architects make decisions</code>. Three major architecture anti-patterns that often unfold during decision-making are the <code>Covering Your Assets</code> anti-pattern, the <code>Groundhog Day</code> anti-pattern, and the <code>Email-Driven Architecture</code> anti-pattern. These typically follow a progression: <code>overcoming the first leads to the second, and overcoming the second leads to the third</code>. Navigating architecture decisions successfully requires architects to address each of these anti-patterns.</p> <p>1. Covering Your Assets Anti-Pattern</p> <p><code>This occurs when architects avoid or delay decisions due to the fear of making the wrong choice</code>. To overcome this anti-pattern, <code>architects can either wait until the last responsible moment to decide or collaborate continually with development teams to ensure the decision aligns with implementation realities</code>.</p> <p><code>Waiting until the last responsible moment means gathering enough information to justify and validate the decision without causing delays or succumbing to analysis paralysis</code>. Collaborating with development teams is crucial because architects can't possibly anticipate every detail about a technology. <code>Close collaboration enables swift adjustments to the decision if issues arise</code>.</p> <p>For instance, if an architect decides to cache product-related reference data in all service instances using a read-only replicated cache, collaboration with development teams may reveal scalability issues that prompt a revision of the decision.</p> <p>2. Groundhog Day Anti-Pattern</p> <p>Once architects overcome the first anti-pattern, they may encounter the Groundhog Day anti-pattern. <code>This unfolds when people repeatedly discuss a decision without a clear understanding of why it was made</code>.</p> <p>The Groundhog Day anti-pattern <code>arises when architects fail to provide a comprehensive justification for their decisions</code>. When justifying architecture decisions, <code>it's crucial to offer both technical and business justifications</code>.</p> <p>For instance, a decision to break apart a monolithic application into separate services <code>should not only highlight technical benefits but also articulate the business value, such as faster delivery of new functionality or cost reduction</code>. Providing business value is a litmus test for determining the validity of an architecture decision. If a decision lacks business value, it might not be a sound one and should be reconsidered.</p> <p>3. Email-Driven Architecture Anti-Pattern</p> <p>Once architects make decisions and fully justify them, a third architecture anti-pattern emerges: Email-Driven Architecture. <code>This anti-pattern occurs when people are unaware of an architecture decision, leading to implementation challenges</code>.</p> <p><code>Effectively communicating architecture decisions is crucial to avoid the Email-Driven Architecture anti-pattern</code>. Rather than including the decision in the body of an email, <code>architects should provide a link to a single system of record for the decision, whether it's a wiki page or a document</code>. This ensures a centralized and accessible repository for the decision and its details. Moreover, <code>notifying only relevant stakeholders further enhances communication effectiveness, preventing information overload</code>.</p> <p>By addressing these anti-patterns, architects can enhance the decision-making process, fostering clarity, collaboration, and successful implementation.</p>"},{"location":"arch_decisions/#architecturally-significant","title":"Architecturally Significant","text":"<p>There exists a common misconception among architects that decisions involving specific technologies are merely technical choices rather than architecture decisions. However, this isn't always the case. <code>If an architect decides to adopt a particular technology because it directly supports a specific architecture characteristic, such as performance or scalability, then it qualifies as an architecture decision</code>.</p> <p>The concept of <code>Architecturally Significant helps delineate which decisions fall under the architect's purview</code>. <code>These decisions notably impact the patterns or styles of architecture in use</code>. For instance, choosing to share data among a set of microservices is an architecturally significant decision. This choice influences the bounded context of each microservice, thereby affecting the overall structure of the application.</p> <p><code>Dependencies</code>, another aspect, <code>revolve around coupling points between components or services within the system</code>. These dependencies have far-reaching effects on scalability, modularity, agility, testability, reliability, and more.</p> <p><code>Interfaces</code> represent <code>how services and components are accessed and orchestrated</code>, typically through gateways, integration hubs, service buses, or API proxies. <code>Decisions related to interfaces involve defining contracts, including strategies for versioning and deprecation</code>. Due to their impact on users within the system, <code>interfaces are considered architecturally significant</code>.</p> <p>Lastly, <code>construction techniques</code> encompass decisions about <code>platforms, frameworks, tools, and even processes</code>. While these decisions may seem technical, <code>they can have ramifications for various aspects of the architecture</code>.</p> <p><code>Understanding what constitutes an architecturally significant decision allows architects to focus on the key elements that shape the overall structure, dependencies, interfaces, and construction techniques of a system</code>. This clarity ensures that architects effectively contribute to the architectural integrity and success of the project.</p>"},{"location":"arch_decisions/#architecture-decision-records","title":"Architecture Decision Records","text":"<p>Effectively documenting architecture decisions is crucial for <code>maintaining clarity and coherence in a project</code>. Architecture Decision Records (ADRs) provide a structured way to capture and communicate these decisions. ADRs is a concise document typically spanning <code>one to two pages</code> that outlines a particular architectural decision. Although ADRs can be composed in <code>plain text</code>, they are commonly crafted using text document formats like <code>AsciiDoc</code>, <code>Markdown</code>, <code>wiki page template</code>. Additionally, specialized tools such as ADR-tools exist to facilitate the management of Architecture Decision Records</p>"},{"location":"arch_decisions/#basic-structure","title":"Basic Structure","text":"<p>The basic structure of an ADR consists of five main sections: <code>Title</code>, <code>Status</code>, <code>Context</code>, <code>Decision</code>, and <code>Consequences</code>. Two more sections can be added: <code>Compliance</code> and <code>Notes</code>. This basic template is flexible enough to <code>include any other sections that may be deemed necessary</code>.</p> <p>Title</p> <p>A concise, <code>numbered description</code> of the architecture decision, <code>providing clarity without ambiguity</code>.</p> <p>Status</p> <p>Clearly define the status as <code>Proposed</code>, <code>Accepted</code>, or <code>Superseded</code>. Proposed decisions may require approval, and <code>Superseded decisions should reference the decision that replaces them</code>.</p> <p>Context</p> <p><code>Describe the driving forces behind the decision</code>, outlining the <code>specific situation</code> and <code>possible alternatives</code>. This section provides context for the decision-making process.</p> <p>Decision</p> <p>Clearly articulate the decision along with its <code>justification</code>. Emphasize the <code>why</code> behind the decision rather than the <code>how</code>.</p> <p>Consequences</p> <p>Detail the <code>impact of the decision</code>, <code>considering both positive and negative consequences</code>. Include <code>trade-off</code> analysis to weigh the impacts against the benefits.</p> <p>Compliance</p> <p>Address how compliance with the decision will be <code>ensured</code>. <code>Specify whether compliance checks are manual or automated using fitness functions</code>. If automated, provide details on how fitness functions will be written and implemented.</p> <p>Notes</p> <p>Include <code>metadata</code> such as the author's name and any additional relevant information.</p>"},{"location":"arch_decisions/#storing-adrs","title":"Storing ADRs","text":"<p>Once an architect creates an ADR, it must be <code>stored</code> somewhere. Regardless of where ADRs are stored, <code>each architecture decision should have its own file or wiki page</code>.</p> <p>Some architects like to keep ADRs in the <code>Git repository</code> with the source code. Keeping ADRs in a Git repository <code>allows the ADR to be versioned and tracked as well</code>. However, for larger organizations, caution <code>against</code> this practice for several reasons. Firstly, <code>not everyone who needs to see the architecture decision may have access to the Git repository</code>. Secondly, the Git repository may not be a suitable place for storing ADRs that have a <code>context outside of the application Git repository</code>. This applies to integration architecture decisions, enterprise architecture decisions, or those decisions common to every application.</p> <p>For these reasons, is recommend storing ADRs either in a <code>wiki</code>, using a wiki template, or in a <code>shared directory on a shared file server</code>. This ensures accessibility for all stakeholders through a wiki or other document rendering software.</p>"},{"location":"arch_risk/","title":"Analyzing Architecture Risk","text":"<p><code>Every architectural design carries inherent risks</code>, whether they involving to availability, scalability, or data integrity. <code>Analyzing these risks constitutes a crucial aspect of the architectural process</code>. <code>Continuous risk analysis empowers architects to identify weaknesses within the design and proactively take corrective measures to mitigate potential issues</code>.</p>"},{"location":"arch_risk/#risk-matrix","title":"Risk Matrix","text":"<p><code>An initial challenge in evaluating architecture risks lies in the subjective classification of risks as low, medium, or high</code>. This subjectiveness can lead to ambiguity regarding the true risk levels in different parts of the architecture. <code>Architects can utilize a risk matrix to inject objectivity into the process and categorize risks</code> associated with specific architectural components.</p> <p><code>The architecture risk matrix employs two dimensions to assess risk: the overall impact of risk and the likelihood of its occurrence</code>. Each dimension is assigned a rating of low (1), medium (2), or high (3). These ratings are multiplied within each matrix grid, yielding an objective numerical representation of the risk.</p> <p>Example</p> <p></p> <p>Matrix for determining architecture risk from Fundamentals of Software Architecture.</p> <p>Database Risk</p> <p>Consider a scenario where there are concerns about the availability of a central database in the application. Initially, assess the impact dimension by <code>evaluating the potential consequences if the database were to go down</code>. An architect may determine this as a high-risk scenario, assigning a rating of 3 (medium), 6 (high), or 9 (high). However, <code>factoring in the second dimension, which evaluates the likelihood of the risk occurring</code>, the architect may realize that the database is hosted on highly available servers in a clustered configuration, minimizing the chances of unavailability. Consequently, <code>the intersection between high impact and low likelihood results in an overall risk rating of 3 (medium risk)</code>.</p>"},{"location":"arch_risk/#risk-assessments","title":"Risk Assessments","text":"<p><code>A risk assessment serves as a concise overview of an architecture's overall risk</code>, contextualized against specific assessment criteria. Leveraging the risk matrix becomes pivotal in constructing meaningful risk assessments.</p> <p>While the format of risk assessments can vary, <code>they generally encapsulate the risk, as qualified by the risk matrix, associated with particular assessment criteria within the application's services or domain areas</code>. The typical report format employs use (1-2) denoting <code>low risk</code>, (3-4) indicating <code>medium risk</code>, and (6-9) signifying <code>high risk</code>. Often color-coded as green (low), yellow (medium), and red (high), these shades facilitate interpretation for both color and non-color users. <code>Cumulative risk can be calculated for each criterion and service/domain area</code>.</p> <p>Example</p> <p></p> <p>Example of a standard risk assessment from Fundamentals of Software Architecture.</p> <p>Notice the accumulated risk for data integrity is the highest at 17, while availability registers the least risk at 10. Relative risk for each domain area can also be determined with customer registration posing the highest risk and order fulfillment the lowest.</p> <p><code>These numbers offer a basis for tracking improvements or deteriorations within specific risk categories or domain areas</code>.</p> <p>In practice, <code>not all risk analysis results are presented simultaneously</code>. Filtering becomes imperative to convey a targeted message in a given context. For instance, <code>in a meeting focusing on high-risk areas, filtering can spotlight only those areas, enhancing clarity and maintaining a favorable signal-to-noise ratio and presenting a clear picture of the state of the system (good or bad)</code>.</p>"},{"location":"arch_risk/#tracking-trends-improvement-or-deterioration","title":"Tracking Trends: Improvement or Deterioration","text":"<p><code>The presented assessment report offers a snapshot in time, lacking insights into whether conditions are improving or getting worse</code>. To address this, incorporate directional indicators such as plus (+) and minus (-) signs next to the risk ratings.</p> <p>Example</p> <p></p> <p>Showing direction of risk with plus and minus signs from Fundamentals of Software Architecture.</p> <p>Examining the example, <code>while the performance for customer registration is medium (4), the minus sign signifies a worsening trend, approaching high risk</code>. Conversely, the high scalability rating for catalog checkout is accompanied by a plus sign, signaling improvement. <code>Ratings without directional signs indicate stable risk conditions, neither improving nor worsening</code>.</p> <p>An Alternative Approach</p> <p></p> <p>Showing direction of risk with arrows and numbers from Fundamentals of Software Architecture.</p> <p>Continuous measurements facilitated by fitness functions <code>shows direction of risk, allowing for trend analysis and determining the directional trajectory of each risk factor</code>.</p>"},{"location":"arch_risk/#risk-storming","title":"Risk Storming","text":"<p>Risk storming plays <code>a crucial role in assessing the overall risk of a system, ensuring that no potential areas of concern are overlooked</code>. A single architect may not possess complete knowledge of every system aspect, making <code>collaboration essential in this process</code>.</p> <p>Risk storming is a <code>collaborative exercise focuses on specific dimensions of risk</code>, such as unproven technology, performance, scalability, availability, transitive dependencies, data loss, single points of failure, and security. <code>Engaging multiple architects, along with senior developers and tech leads, brings diverse perspectives and enhances the understanding of architectural intricacies for everyone</code>.</p> <p>The risk storming process comprises <code>two key phases: individual and collaborative</code>. In the individual phase, <code>participants independently assess risk using a</code> risk matrix, <code>ensuring unbiased evaluations from anyone</code>. Subsequently, in the collaborative phase, <code>participants work together to identify consensus on risk areas</code>, engage in discussions, and formulate effective solutions for risk mitigation.</p> <p>Throughout the risk storming effort, <code>architecture diagrams are indispensable</code>. Holistic risk assessments utilize comprehensive diagrams, while risk storming within specific application areas employs contextual diagrams. <code>The architect is responsible for maintaining up-to-date and accessible diagrams for all participants</code>.</p> <p>Architecture Diagram Risk</p> <p>In the example, an Elastic Load Balancer, EC2 instances with web servers (Nginx), application services, MySQL database, Redis cache, MongoDB database for logging, and Push Expansion Servers. <code>This example architecture serves to illustrate the risk storming process</code>.</p> <p></p> <p>Architecture diagram for risk storming example from Fundamentals of Software Architecture.</p> <p>Risk storming can be broken down into three activities:</p> <ol> <li>Identification</li> <li>Consensus</li> <li>Mitigation</li> </ol> <p>Identification is always an individual, noncollaborative activity, whereas consensus and mitigation are always collaborative and involve all participants working together.</p>"},{"location":"arch_risk/#identification","title":"Identification","text":"<p>The identification phase of risk storming is a crucial step where <code>participants individually pinpoint areas of risk within the architecture</code>. Here's a breakdown of the identification process:</p> <p>Prepartion and Invitation</p> <ol> <li>The architect leading the risk storming sends invitations one to two days in advance of the collaborative session.</li> <li><code>The invitation includes the architecture diagram (or link) and specifies the risk storming dimension to be analyzed</code>.</li> </ol> <p>Individual Analysis</p> <ol> <li>Using the risk matrix, participants autonomously assess the architecture, categorizing risk as low (1-2), medium (3-4), or high (6-9).</li> </ol> <p>Post-It Note Preparation</p> <ol> <li>Participants prepare <code>small Post-it notes</code>, each representing an identified risk area, with colors indicating the risk level (green for low, yellow for medium, and red for high).</li> </ol> <p><code>It's common for a risk storming session to focus on a single dimension</code> (e.g., performance), but occasionally, due to resource availability or timing constraints, multiple dimensions may be analyzed simultaneously (e.g., performance, scalability, and data loss).</p> <p>Tip</p> <p>However, whenever feasible, <code>it's advisable to limit risk storming efforts to a single dimension</code>. This ensures participants concentrate on specific aspects, preventing confusion regarding multiple risks identified for the same area of the architecture.</p>"},{"location":"arch_risk/#consensus","title":"Consensus","text":"<p>The consensus-building phase in the risk storming is a <code>collaborative effort aimed at achieving agreement among all participants regarding the identified risks</code> within the architecture.</p> <p>Upon commencement of the risk storming session, <code>participants affix their Post-it notes onto the architecture diagram, marking areas where they individually identified risks</code>.</p> Example <p></p> <p>Initial identification of risk areas from Fundamentals of Software Architecture.</p> <p>Once all Post-it notes are in place, the collaborative aspect of risk storming initiates. <code>The team collectively examines the risk areas, striving to reach a consensus on risk qualification</code>. If an item receives unanimous agreement in terms of risk level, no further discussion is necessary. <code>Items with divergent results prompt discussion</code>. Individuals with varying assessments must elucidate their perspectives. In cases where everyone provides different ratings, a comprehensive discussion is required. <code>Following the discussion, a consensus must be reached</code>.</p> Risk Storming Result <p></p> <p>Consensus of risk areas from Fundamentals of Software Architecture.</p>"},{"location":"arch_risk/#mitigation","title":"Mitigation","text":"<p>Following unanimous agreement among participants regarding the qualification of risk areas in the architecture, the subsequent and <code>crucial phase</code> is risk mitigation. <code>Mitigating risk in architecture often necessitates alterations or enhancements to specific areas that might have initially been considered flawless</code>.</p> <p>This typically collaborative activity <code>explores ways to diminish or eradicate the identified risks</code>. Mitigation efforts <code>can range from comprehensive architectural changes</code> prompted by risk identification <code>to more straightforward refactoring</code>, such as introducing a queue to alleviate throughput bottleneck issues. While these changes enhance the architecture, <code>they usually come with additional costs</code>.</p> <p>Cost Negotiation Example</p> <p>Key stakeholders play a pivotal role in determining whether the incurred cost justifies the risk reduction. For instance, suppose a risk storming session <code>identifies the central database as a medium risk (4) for overall system availability</code>. Participants may <code>propose clustering the database and dividing it into separate physical databases to mitigate the risk</code>, albeit at a cost of <code>$20,000</code>. A negotiation ensues between the architect and key business stakeholders, where the <code>stakeholders ultimately decide the cost outweighs the risk</code>. In response, the <code>architect suggests an alternative approach\u2014skipping clustering and opting for a two-part database split, reducing the cost to $8,000</code> while still mitigating most of the risk. In this case, the <code>stakeholders find the compromise acceptable</code>.</p> <p><code>This scenario illustrates how risk storming not only influences the architecture but also impacts negotiations between architects and business stakeholders</code>. Risk storming, coupled with the risk assessments, proves to be a <code>valuable method for identifying and monitoring risk, enhancing architecture, and facilitating negotiations among key stakeholders</code>.</p>"},{"location":"arch_styles/","title":"Architecture Styles","text":"<p><code>An architecture style refers to the overall structure of a software system, including how the user interface, backend code, and data storage are organized</code>. It encompasses decisions like whether to use a monolithic approach with all components together or a distributed approach with separate services.</p> <p>On the other hand, <code>architecture patterns are more detailed design structures that offer solutions within a specific architecture style</code>. These patterns address specific concerns, such as achieving scalability or optimizing performance for certain operations or services. They serve as practical templates for solving particular problems within the chosen architecture style.</p> <p>For new architects, <code>grasping different architecture styles is essential, as they form the foundation for making effective design decisions</code>. Each architecture style comes with its own set of trade-offs, which help architects choose the most suitable approach for a given business problem.</p>"},{"location":"arch_styles/choosing_arch_style/","title":"Choosing the Appropriate Architecture Style","text":"<p><code>Determining the right architecture style can be a bit tricky</code>. With numerous choices available (and new ones popping up almost every day), <code>it's not that straightforward</code>. Choosing the appropriate architectural style <code>involves considering various factors within an organization and the specific software it's developing</code>. This decision-making process requires a careful <code>evaluation of trade-offs related to architectural characteristics, domain considerations, strategic goals, and several other variables</code>.</p> <p>Even though the decision is deeply contextual, there are a few <code>pieces of general advice</code> that might come in handy as you navigate the landscape of architectural styles.</p>"},{"location":"arch_styles/choosing_arch_style/#shifting-fashion-in-architecture","title":"Shifting \u201cFashion\u201d in Architecture","text":"<p><code>Understanding the dynamic landscape of architecture trends is crucial for architects</code>, regardless of where an organization currently stands in terms of architectural preferences. The ever-changing nature of preferred architecture styles is influenced by various factors:</p> Observations from the past <p><code>New architecture styles often emerge from lessons learned and challenges faced in previous projects</code>. Architects draw from their past experiences to shape future systems, addressing deficiencies and optimizing design based on historical insights.</p> Changes in the ecosystem <p>The software development ecosystem is marked by <code>constant change, making predictions challenging</code>. Tools and technologies that were once unheard of can quickly become industry standards. For example, the rapid rise of <code>Kubernetes</code>, which few anticipated a few years ago, illustrates the unpredictable nature of ecosystem changes.</p> Introduction of New Capabilities <p><code>When new capabilities arise, architecture may not merely replace one tool with another but rather shift to an entirely new paradigm</code>. Unexpected advancements, such as the introduction of containerization with Docker, have profound impacts on architects, tools, and engineering practices. <code>Architects must not only monitor new tools but also remain open to paradigmatic changes that might redefine their approach</code>.</p> Accelerated Rate of Change <p>The rate of change in the ecosystem continues to accelerate, driven by the emergence of new tools, engineering practices, and capabilities. <code>Architects operate in a state of constant flux, adapting to evolving trends and staying agile in response to ongoing transformations</code>.</p> Domain changes <p><code>Changes in the business domain, driven by factors like business evolution or mergers, can influence the architectural choices made by developers</code>.</p> Technology changes <p>Organizations strive to keep up with technological advancements that offer obvious benefits. <code>Adopting technologies with clear advantages becomes a strategic move for staying competitive</code>.</p> External factors <p>External factors, such as changes in licensing costs, <code>may force architects and developers to reconsider their tooling choices and migrate to alternative options</code>.</p>"},{"location":"arch_styles/choosing_arch_style/#decision-criteria","title":"Decision Criteria","text":"<p>When architects embark on the journey of <code>selecting an architectural style</code>, they must carefully weigh various <code>factors that contribute to shaping the structure of the domain design</code>. At its core, an architect is tasked with designing two fundamental elements: <code>the specified domain and all the supporting structural elements essential for the system's success</code>.</p> <p>Architects should approach the decision-making process with a clear understanding of the following key aspects:</p> Understanding the Domain <p><code>While architects don't need to be domain experts, they must grasp critical aspects of the domain</code>, particularly those influencing operational architecture characteristics.</p> Identifying Architecture Characteristics <p><code>Discovering and articulating the architecture characteristics essential to support the domain and external factors is crucial</code>.</p> Data Architecture <p><code>Collaboration between architects and database administrators is vital for addressing database, schema, and other data-related concerns</code>. Architects must comprehend the potential impact of data design, especially when dealing with legacy data architectures.</p> Organizational Factors <p>External factors, such as the cost of cloud vendors or organizational plans for mergers and acquisitions, can significantly influence design decisions. <code>Architects need to align their designs with practical considerations</code>.</p> Knowledge of Process, Teams, and Operational Concerns <p>Project-specific factors, including the software development process, collaboration with operations, and the QA process, <code>play a pivotal role in influencing architectural decisions</code>.</p> Domain/Architecture Isomorphism <p>This concept explores how the structural characteristics of an architecture correspond to a particular architecture style. <code>Some domains naturally match certain architectural topologies, while others may be ill-suited for specific styles</code>.</p> <p>For instance, the <code>microkernel architecture style perfectly fits a system requiring customizability</code>, allowing architects to design plug-in customizations. Another example is genome analysis, where numerous discrete operations are essential, making space-based architecture with multiple discrete processors an ideal choice. Conversely, <code>some problem domains are inherently incompatible with specific architecture styles</code>. Highly scalable systems, for example, face challenges with large monolithic designs, as supporting numerous concurrent users becomes complex in a tightly coupled code base. </p> <p>Considering these aspects, <code>architects must make several key determinations</code>:</p> <p>Monolith vs Distributed Architecture</p> <p><code>Deciding whether a single set of architecture characteristics suffices or if different parts of the system require diverse characteristics is crucial</code>. A monolith may be suitable for a unified set, while distributed architecture becomes necessary for diverse characteristics.</p> <p>Data Storage Decisions</p> <p>In a monolithic architecture, a single relational database or a few may suffice, while in a distributed architecture, <code>architects must decide where data should reside and how it flows throughout the system</code>.</p> <p>Communication Styles between Services\u2014Synchronous or Asynchronous?</p> <p><code>Determining the communication style between services is the next consideration</code>. While synchronous communication is more convenient, asynchronous communication offers unique benefits but comes with its set of challenges.</p> <p><code>The output of this design process encompasses the architecture's topology</code>, including the chosen style and hybridizations, architecture decision records documenting critical design aspects, and architecture fitness functions safeguarding essential principles and operational characteristics.</p>"},{"location":"arch_styles/event_driven_arch/","title":"Event-Driven Architecture Style","text":"<p>The event-driven architecture style is a well-liked method for <code>building applications that need to be both highly scalable and high-performing</code>. It's quite flexible and can be <code>used for both small and large applications</code>, making it a popular choice across the board. This style involves <code>components that process events independently, without being tightly connected</code>. <code>It can be its own architecture style or be part of other styles</code>, like event-driven microservices architecture.</p> <p>In many applications, there's a <code>request-based approach, where a central system manages and directs various requests to the right places</code>. This can be a user interface, an API layer, or an enterprise service bus. <code>These places handle the requests, dealing with tasks like retrieving or updating data in a database</code>.</p> <p></p> <p>Request-based model from Fundamentals of Software Architecture.</p> Request-Based Example <p>For instance, when a customer requests their order history for the past six months, <code>it involves retrieving data within a specific context, making it a data-driven, deterministic request</code>. This aligns with the request-based model.</p> <p><code>An event-based model responds to specific situations, triggering actions based on those events</code>.</p> Event-Based Model Example <p>For example, in an online auction, submitting a bid isn't a direct request to the system but <code>an event that occurs after the current asking price is announced</code>. <code>The system must react to this event by comparing the bid to others received simultaneously, determining the current highest bidder</code>.</p>"},{"location":"arch_styles/event_driven_arch/#topology","title":"Topology","text":"<p><code>Two main topologies are prevalent in event-driven architecture: the mediator topology and the broker topology</code>. Understanding the distinct characteristics and implementation strategies of these topologies is crucial to determining the most suitable choice for a given situation.</p> <p>The Mediator Topology</p> <p>The mediator topology is commonly applied when you need to manage the workflow of an event process.</p> <p>The Broker Topology</p> <p>The broker topology is favored when you need swift responsiveness and dynamic control over event processing.</p>"},{"location":"arch_styles/event_driven_arch/#broker-topology","title":"Broker Topology","text":"<p>The broker topology in event-driven architecture <code>differs from the mediator topology by not having a central event mediator</code>. Instead, the <code>message flow is spread across the event processor components in a chain-like broadcasting style through a lightweight message broker</code>. This topology is <code>beneficial for relatively straightforward event processing flows</code> where central event orchestration and coordination are unnecessary.</p> <p>There are four main parts in the broker topology: <code>an initiating event, the event broker, an event processor, and a processing event</code>.</p> <p>Initiating Event</p> <p>This is the starting point of the entire event flow.</p> <p>Event Broker</p> <p>The initiating event is sent to an event channel in the event broker for processing.</p> <p>Event Processor</p> <p>Since there is no mediator component, a single event processor receives the initiating event from the event broker and begins the processing of that event. The event processor executes a specific task related to the event and asynchronously broadcasts its actions to the entire system, creating a processing event.</p> <p>Processing Event</p> <p>This processing event is then sent to the event broker for further processing, if necessary. Other event processors, upon listening to the processing event, react to it by performing actions and then advertise, through a new processing event, what they did. This process continues until no one is interested in the actions of a final event processor.</p> <p>In the broker topology, it is considered <code>good practice for each event processor to advertise its actions to the entire system</code>, even if other event processors may not be concerned. This practice <code>ensures architectural extensibility in case additional functionality is required for processing that event</code>.</p> <p>Email Notifying</p> <p>Suppose an email needs to be generated and sent to a customer to inform them about a specific action. 1. The <code>Notification event processor</code> generates and dispatches the email. 1. It then <code>advertises this action to the entire system by creating a new processing event</code>, sending it to a topic. 1. However, since no other event processors are tuned in to events on that topic, the message <code>simply fades away without any further impact</code>.</p> <p>Here's a notable illustration of <code>architectural extensibility</code>. <code>Although it might appear inefficient to send messages that go unnoticed, it holds significant value</code>. Consider a scenario where a new requirement emerges to analyze emails sent to customers. With the current system:</p> <ol> <li>A new <code>event processor for analyzing emails can seamlessly be introduced</code> with minimal effort.</li> <li>The email information is readily accessible via the email topic, allowing the new analyzer to function without the need for additional infrastructure or changes to other event processors.</li> </ol> <p>More Deep Example</p> <p></p> <p>Example of the broker topology Fundamentals of Software Architecture.</p> <ol> <li>The <code>initial event</code> is \"Purchasing Book.\"</li> <li>The <code>event broker</code> is represented by the <code>[PlaceOrder]</code> pipe.</li> <li><code>Event processors</code> are depicted as boxes, like <code>OrderPlacement</code>, <code>Payment</code>, <code>Notification</code>, etc.</li> <li><code>Processing events</code>  are illustrated by pipes with arrows and names in lowercase, like <code>[order-created]</code>, <code>[inventory-updates]</code>, <code>[payment-denied]</code>, etc.</li> </ol> <p>It's evident that <code>all event processors are highly decoupled and operate independently</code>. <code>Once an event processor hands off the event, it ends involvement in the processing of that specific event, remaining available to react to other initiating or processing events</code>. Moreover, <code>each event processor can scale independently</code> to handle varying load conditions or backups in the event processing.</p> <p>While the broker topology offers benefits in terms of performance, responsiveness, and scalability, there are <code>drawbacks</code>. Firstly, <code>there is no control over the overall workflow associated with the initiating event</code>. The system lacks awareness of when the business transaction of placing an order is truly complete. <code>Error handling poses a significant challenge in the broker topology</code>. Without a mediator monitoring or controlling the business transaction, a failure goes unnoticed, leading to a stuck business process that requires automated or manual intervention to resolve.</p> <p><code>Recovering from a business transaction (recoverability) is not supported in the broker topology</code>. As other actions are asynchronously taken during the initial processing of the initiating event, resubmitting the initiating event becomes impractical. <code>No component in the broker topology is aware of or owns the state of the original business request, leaving no one responsible for restarting the business transaction and knowing its progress</code>.</p> Advantages Disadvantages <code>Highly decoupled event processors</code> Workflow control <code>High scalability</code> Error handling <code>High responsiveness</code> Recoverability <code>High performance</code> Restart capabilities <code>High fault tolerance</code> Data inconsistency"},{"location":"arch_styles/event_driven_arch/#mediator-topology","title":"Mediator Topology","text":"<p>In the mediator topology, a central figure is the <code>event mediator, overseeing and orchestrating the workflow for initiating events that necessitate the coordination of multiple event processors</code>. The key components of the mediator topology include an initiating event, an event queue, an event mediator, event channels, and event processors.</p> <p>Initiating Event</p> <ol> <li>This is the event that initiates the entire eventing process.</li> <li><code>The initiating event is directed to an initiating event queue, which is then received by the event mediator</code>.</li> </ol> <p>Event Mediator</p> <ol> <li>Manages the workflow, generating corresponding processing events dispatched to dedicated event channels (usually queues) in a point-to-point messaging style.</li> </ol> <p>Event Processors</p> <ol> <li>Attend to their tasks by <code>monitoring dedicated event channels, executing event-specific processes, and typically communicating back to the mediator upon task completion</code>.</li> <li>Unlike the broadcast approach of the broker topology, <code>event processors in the mediator setup operate discreetly without announcing their actions to the entire system</code>.</li> </ol> <p>Practical implementations often <code>deploy multiple mediators, each linked to a specific domain or category of events</code>. This strategic approach <code>mitigates the risk of a single point of failure</code>, enhancing overall system resilience and performance.</p> <p>The mediator component, distinctive from the broker topology, <code>boasts both knowledge and command over the workflow</code>. This capability empowers the mediator to uphold event states and proficiently manage aspects like error handling, recoverability, and restart functionalities.</p> <p>A fundamental disparity surfaces between the processing events in broker and mediator topologies concerning their meaning and utilization. In the <code>broker paradigm, processing events serve as published occurrences in the system</code> (e.g., order-created, payment-applied, email-sent), <code>triggering subsequent actions and reactions among event processors</code>. Using the <code>mediator topology, processing events</code> (e.g., place-order, send-email, fulfill-order) <code>are akin to commands, dictating necessary actions rather than merely reporting past events</code>. Notably, in the <code>mediator domain, a command necessitates processing, while an event in the broker setup can be disregarded</code>.</p> <p>Challenges within the Mediator Domain</p> <p>Although event processors can scale comparably to the broker setup, the <code>mediator's scaling introduces occasional bottlenecks</code> in the overarching event processing flow. Additionally, <code>event processors in the mediator setup lack the high level of independence</code> seen in the broker model, impacting overall performance due to the mediator's active role in controlling event processing.</p> Advantages Disadvantages <code>Workflow control</code> More coupling of event processors <code>Error handling</code> Lower scalability <code>Recoverability</code> Lower performance <code>Restart capabilities</code> Lower fault tolerance <code>Better data consistency</code> Modeling complex workflows"},{"location":"arch_styles/event_driven_arch/#asynchronous-capabilities","title":"Asynchronous Capabilities","text":"<p>The event-driven architecture style presents a distinctive feature compared to other architectural approaches by <code>relying entirely on asynchronous communication</code>. This encompasses both <code>fire-and-forget processing</code>, where no response is required, and <code>request/reply</code> processing, where a response is expected from the event consumer. Leveraging asynchronous communication proves to be a <code>potent technique for enhancing overall system responsiveness</code>.</p>"},{"location":"arch_styles/event_driven_arch/#responsiveness-vs-performance","title":"Responsiveness vs Performance","text":"<p>In scenarios where the <code>user doesn't necessitate immediate feedback</code> beyond an acknowledgment or a simple thank-you message, why subject them to unnecessary waiting? <code>Responsiveness focuses on promptly notifying the user that their action has been acknowledged and will undergo processing shortly</code>. Conversely, <code>performance revolves around expediting the end-to-end process</code>.</p> <p><code>The challenge in asynchronous behavior arises when the user's action encounters rejection</code>, as there's no direct route to communicate this back to the end user. While a message signaling an issue could be dispatched, in more intricate scenarios, this might not constitute a comprehensive solution. The primary hurdle in asynchronous communications lies in error handling. <code>Although responsiveness sees a significant boost, effectively addressing error conditions adds complexity to the event-driven system</code>.</p>"},{"location":"arch_styles/event_driven_arch/#error-handling-workflow-event-pattern","title":"Error Handling - Workflow Event Pattern","text":"<p>The workflow event pattern within reactive architecture provides a solution to the challenges associated with error handling in an asynchronous workflow. <code>This pattern, inherent to reactive architecture, effectively addresses both resiliency and responsiveness, ensuring that the system remains robust in handling errors without compromising responsiveness</code>.</p> <p>In this approach, <code>the event producer asynchronously transmits data through a message channel to the event consumer</code>. When the event consumer encounters an error in processing, <code>it promptly delegates the error to the workflow processor and proceeds to process the next message in the event queue</code>. This ensures that overall <code>responsiveness is maintained</code>, as errors don't become impediments to processing subsequent messages.  <code>If the event consumer were to spend time resolving the error, it would impede not only the responsiveness of the next message but also impact all other messages waiting in the queue for processing</code>.</p> <p>Upon encountering an error, <code>the workflow processor engages in a diagnostic process to identify issues within the message</code>. This diagnostic phase may involve recognizing static, deterministic errors or deploying machine learning algorithms to detect anomalies in the data. <code>The workflow processor then programmatically applies changes to the original data in an attempt  to repair it</code>. The corrected data is subsequently re-entered into the originating queue. From the perspective of the event consumer, this <code>corrected message is treated as new, prompting another processing attempt</code>. In scenarios where the <code>workflow processor cannot definitively pinpoint the issue, the message is redirected to an alternative queue, commonly known as a dashboard</code>.</p> <p><code>This dashboard, resembling familiar email applications, usually resides on the desktop of a key individual</code>. Here, the individual reviews the message, introduces manual fixes if needed, and then reissues it to the original queue, often utilizing a \"reply-to\" message header variable.</p> <p>A noteworthy consequence  of the workflow event pattern is <code>messages encountering errors undergo processing out of their original sequence upon resubmission</code>. Preserving the exact order of messages within a specific context proves to be a complex task. <code>A potential solution to this challenge involves storing the errored messages temporarily in a dedicated queue</code>. Any data processing with the same identification (like ID) would be stored in a temporary queue for later processing (in FIFO order). <code>Once the error is fixed and processed, the service then de-queues the remaining trades for that same identification and processes them in order</code>.</p> Example <p>Consider a scenario where a <code>trading advisor</code>, situated in one part of the country, <code>manages trade orders for a prominent trading firm</code> located elsewhere. The <code>advisor efficiently compiles trade orders into a basket and dispatches them asynchronously to the large trading firm for execution through a broker</code>. The contractual format for trade instructions encompasses fields such as: <code>ACCOUNT (String), SIDE (String), SYMBOL (String), and SHARES (Long)</code>.</p> <p>Imagine the large trading firm receives a basket of Apple (AAPL) trade orders from the advisor: <code>12654A87FR4,BUY,AAPL,1254</code></p> <p><code>87R54E3068U,BUY,AAPL,3122</code></p> <p><code>2WE35HF6DHF,BUY,AAPL,8756 SHARES</code></p> <p><code>6R4NB7609JJ,BUY,AAPL,5433</code></p> <p>In a scenario <code>without of error-handling capabilities, an error would surface on the line with SHARES</code>. In this asynchronous context, when an exception occurs, the trade placement service lacks the means for synchronous user intervention. <code>The only recourse might be logging the error condition</code>.</p> <p>Integrating the workflow event pattern provides a programmatic resolution to such errors. <code>As the large trading firm lacks control over the trading advisor's data, it must autonomously fix the error itself</code>. When the error occurs (2WE35HF6DHF,BUY,AAPL,8756 SHARES), <code>the Trade Placement service promptly delegates the error via asynchronous messaging to the Trade Placement Error service</code>. This delegation includes the error information.</p> <p>The <code>Trade Placement Error</code> service, <code>operating as the workflow delegate</code>, receives and inspects the exception, identifying it as a \"SHARES\" issue in the shares field. Subsequently, the <code>Trade Placement Error service removes the term \"SHARES\" and resubmits the trade for reprocessing</code>, effectively addressing the error within the workflow event pattern.</p> <p></p> <p>Error handling with the workflow event pattern from Fundamentals of Software Architecture.</p>"},{"location":"arch_styles/event_driven_arch/#preventing-data-loss","title":"Preventing Data Loss","text":"<p><code>Mitigating data loss is a critical consideration in the realm of asynchronous communications</code>, particularly within an event-driven architecture. <code>Several points in this system can lead to data loss, meaning messages might accidentally be dropped or fail to reach their intended destination</code>. The good news is that <code>there are basic methods available to prevent data loss</code> in asynchronous messaging situations.</p>"},{"location":"arch_styles/event_driven_arch/#example","title":"Example","text":"<p>Consider a scenario where <code>Event Processor A</code> sends a message to a <code>queue</code>, subsequently processed by <code>Event Processor B</code>, which inserts the message data into a database. Three potential areas of data loss emerge:</p> <p>1. Message Fails to Reach the Queue</p> <p>The <code>message fails to reach the queue from Event Processor A</code>, or if it does, the <code>broker goes down before the next event processor retrieves the message</code>.</p> <p>Guaranteed Delivery with <code>Persistent Message Queues</code> and <code>Synchronous Send</code></p> <ol> <li><code>Leveraging persistent message queues ensures guaranteed delivery</code>. Messages are stored in both memory and a physical data store, facilitating retrieval even if the broker experiences downtime.</li> <li><code>Synchronous send involves a blocking wait in the message producer until the broker confirms the message's persistence</code>. This combination prevents message loss between the producer and the queue.</li> </ol> <p>2. Event Processor Crashes Before Processing</p> <p>Event Processor B dequeues the next message but crashes before processing it.</p> <p><code>Client Acknowledge Mode</code> for Crash Resilience</p> <ol> <li>By default, when a message is de-queued, it is immediately removed from the queue (<code>auto acknowledge mode</code>).</li> <li>Client acknowledge mode <code>retains the message in the queue and associates the client ID with it</code>, preventing other consumers from reading the message.</li> <li>In the <code>event of a crash, the message remains preserved in the queue</code>, averting message loss in this part of the message flow.</li> </ol> <p>3. Data Error When Saving to the Database</p> <p>Event Processor B encounters difficulty persisting the message to the database due to a data error.</p> <p><code>ACID Transactions</code> and <code>Last Participant Support (LPS)</code> for Database Persistence</p> <ol> <li>ACID transactions, specifically atomicity, consistency, isolation, and durability, are employed via a <code>database commit</code>, ensuring the data's persistence in the database.</li> <li>Last participant support (LPS) <code>acknowledges the completion of processing and message persistence</code>, removing the message from the persisted queue. This guarantees the entire workflow, from the Event Processor A to the database.</li> </ol>"},{"location":"arch_styles/event_driven_arch/#broadcast-capabilities","title":"Broadcast Capabilities","text":"<p>In event-driven architecture, another distinctive feature is the ability to <code>broadcast events without knowing who will receive the message or what they will do with it, if anything</code>.</p> <p>Broadcasting represents a <code>significant level of decoupling between event processors</code>. The producer of the broadcast message typically lacks knowledge about which event processors will receive the message and, more crucially, what actions they will take in response. <code>Broadcast capabilities play a vital role in patterns for eventual consistency, complex event processing (CEP), and various other scenarios</code>.</p>"},{"location":"arch_styles/event_driven_arch/#request-reply","title":"Request-Reply","text":"<p>In scenarios where it's <code>essential to receive information</code>, such as an order ID when ordering a book or a confirmation number when booking a flight, <code>synchronous communication</code> between services or event processors becomes necessary.</p> <p><code>Within event-driven architecture, synchronous communication is facilitated through request-reply messaging</code>. In request-reply messaging, each event channel comprises two queues:</p> <ol> <li>a request queue</li> <li>a reply queue</li> </ol> <p>Workflow</p> <ol> <li>The <code>initial request</code> for information is asynchronously <code>sent to the request queue</code>.</li> <li>Control is then returned to the <code>message producer</code> after sending the request.</li> <li>The <code>message producer</code> waits for the response by blocking on the <code>reply queue</code>.</li> <li>The <code>message consumer</code> receives and processes the message, <code>sending the response to the reply queue</code>.</li> <li>Finally, the event producer receives the message containing the response data.</li> </ol> <p></p> <p>Request-reply message processing from Fundamentals of Software Architecture.</p> <p><code>Two primary techniques are commonly used to implement request-reply messaging</code>. The first and <code>most common technique involves utilizing a correlation ID</code> contained in the message header. This correlation ID is a field in the reply message typically set to the message ID of the original request message.</p> <p>The second technique for implementing request-reply messaging is to <code>use a temporary and exclusive queue for the reply queue</code>. A temporary queue is dedicated to the specific request, <code>created when the request is made, and deleted when the request concludes</code>.</p> <p>Warning</p> <p><code>While the temporary queue technique is simpler, it comes with the drawback of the message broker having to create and immediately delete a temporary queue for each request</code>.  In scenarios with high messaging volumes, this can significantly slow down the message broker, impacting overall performance and responsiveness.</p> Using Correlation ID <ol> <li>The <code>event producer sends a message to the request queue and notes the unique message ID</code> (124). Notably, the correlation ID (CID) is null in this case.</li> <li>The <code>event producer then waits for a reply on the reply queue, using a message filter</code>.<ul> <li>The <code>filter looks for messages where the correlation ID in the header matches the original message ID</code> (124).</li> </ul> </li> <li>The <code>event consumer</code> receives and processes the message (ID 124).</li> <li>The <code>event consumer generates a reply message</code>, including the response and <code>setting the correlation ID (CID) in the header to the original message ID</code> (124).</li> <li>The <code>event consumer sends the new message (ID 857) to the reply queue</code>.</li> <li>The <code>event producer</code>, waiting for a reply, <code>receives the message (ID 857) because the correlation ID (124) matches the message selector from step 2</code>.</li> </ol> <p></p> <p>Request-reply message processing using a correlation ID from Fundamentals of Software Architecture.</p> Using Temporary and Exclusive Queue <ol> <li>The <code>event producer creates a temporary queue (or one is automatically created, depending on the message broker) and sends a message to the request queue</code>, including the name of the temporary queue in the reply-to header (or another identifier).</li> <li>The <code>event producer waits for a reply on the temporary queue</code>. This queue is <code>exclusive to the event producer that initiated the request</code>.</li> <li>The <code>event consumer</code> receives the message, processes the request, and sends a response message to the <code>reply queue named in the reply-to header</code>.</li> <li>The e<code>vent producer</code>, waiting on the temporary queue, <code>receives the response message and deletes the temporary queue</code>.  <p>Request-reply message processing using a temporary queue from Fundamentals of Software Architecture.</p> </li> </ol>"},{"location":"arch_styles/event_driven_arch/#choosing-between-request-based-and-event-based","title":"Choosing Between Request-Based and Event-Based","text":"<p>It is advisable to <code>opt for the request-based model when dealing with well-structured, data-driven requests</code>, such as retrieving customer profile data, <code>where certainty and control over the workflow are crucial</code>. On the other hand, the <code>event-based model is recommended for handling flexible, action-based events</code> that demand high levels of responsiveness and scalability, <code>especially in scenarios involving complex and dynamic user processing</code>.</p>"},{"location":"arch_styles/event_driven_arch/#trade-offs-table","title":"Trade-offs Table","text":"<code>Advantages over request-based</code> Trade-offs Better response to dynamic user content Only supports eventual consistency Better scalability and elasticity Less control over processing flow Better agility and change management Less certainty over outcome of event flow Better adaptability and extensibility Difficult to test and debug Better responsiveness and performance Better real-time decision making Better reaction to situational awareness"},{"location":"arch_styles/event_driven_arch/#hybrid-event-driven-architectures","title":"Hybrid Event-Driven Architectures","text":"<p>While many applications use the event-driven architecture as their primary structure, <code>it's quite common to blend it with other styles, forming what's called a hybrid architecture</code>. Examples include combining <code>event-driven architecture with microservices and space-based architecture</code>. You can also create hybrids like an <code>event-driven microkernel</code> or an <code>event-driven pipeline architecture</code>.</p> <p><code>Integrating event-driven architecture into any style has advantages</code>\u2014it eliminates bottlenecks, establishes a backpressure point for potential backups in event requests, and <code>enhances user responsiveness</code> beyond what other styles offer. In both <code>microservices and space-based architecture</code>, messaging plays a crucial role as data pumps, <code>facilitating asynchronous data transmission to another processor</code>, which then updates the database. These architectures leverage event-driven principles to scale services in a microservices architecture and processing units in a space-based architecture, especially when using messaging for interservice communication.</p>"},{"location":"arch_styles/foundations/","title":"Foundations","text":"<p>Architecture styles, sometimes called architecture patterns, <code>define how components relate to each other and cover various architectural characteristics</code>. These style names are like shortcuts for experienced architects. For example, if an architect talks about a 'layered monolith,' it signals specific structural aspects, what works well (or not), common deployment models, data strategies, and more.</p> <p><code>An architecture style describes the structure and typical architectural characteristics</code>, both good and bad. <code>Architects should also understand the fundamental patterns often found within these styles</code>.</p> Fundamental Patterns <p><code>Over time, some basic patterns keep showing up in software architecture. These patterns help us organize code and deployments</code>. For instance, the idea of separating different concerns based on functionality, into layers is an age-old concept in software. It's been around for a long time and still appears in various forms, even in modern architecture.</p>"},{"location":"arch_styles/foundations/#unitary-architecture","title":"Unitary Architecture","text":"<p>In the early days of software, <code>the computer and software were one</code>. But as technology evolved, they separated to handle more complex tasks. Mainframes, for instance, began as single systems but later split data into separate systems. Today, <code>unitary architectures are rare, except in specific situations like embedded systems</code>. Most software systems grow in complexity, so we separate them into different parts to keep them running smoothly.</p>"},{"location":"arch_styles/foundations/#client-server","title":"Client-Server","text":"<p>A fundamental style in architecture <code>separates technical functionality between frontend and backend</code>. This configuration is commonly referred to as a <code>two-tier or client/server architecture</code>. Over the years, this architectural approach has taken on various forms, adapting to different eras and advancements in computing technology.</p>"},{"location":"arch_styles/foundations/#desktop-database-server","title":"Desktop + Database Server","text":"<p>In the past, <code>desktop applications used to handle the user interface, while the data was stored in separate database servers accessible over networks</code>. This allowed desktops to handle user interfaces while heavy data processing happened on more powerful database servers.</p>"},{"location":"arch_styles/foundations/#browser-web-server","title":"Browser + Web Server","text":"<p>In this setup, <code>users interact with a web server, which connects to a database server</code>. It's similar to the desktop architecture but with lighter clients (browsers), making it more accessible. Although the database is separate, it's still considered two-tier because the web and database servers run on one machine in the data center, while the user interface is in the user's browser.</p>"},{"location":"arch_styles/foundations/#three-tier","title":"Three-tier","text":"<p>A popular architecture from the late 1990s is the three-tier architecture, <code>which adds more layers of separation</code>. <code>It includes a database tier with a powerful server, an application tier managed by an application server, and a frontend with HTML and JavaScript for user interfaces</code>.</p>"},{"location":"arch_styles/foundations/#references","title":"References","text":"<ul> <li>Fundamentals of Software Architecture</li> </ul>"},{"location":"arch_styles/layered_arch/","title":"Layered Architecture Style","text":"<p>Layered architecture, or the <code>n-tiered architecture style</code>, is a widely used and popular architecture style in software development. Its popularity stems from its <code>simplicity, familiarity, and cost-effectiveness</code>. In most organizations, there are user interface (UI) developers, backend developers, rules developers, and database experts (DBAs). <code>This style seamlessly accommodates various roles in an organization</code>, making it a natural choice for many business applications. This architecture style is particularly <code>well-suited for applications that require a clear separation of concerns and modularity</code>. It allows for the division of an application into distinct layers, with each layer responsible for specific functions. Typically, these layers include:</p> <p>Presentation Layer (UI)</p> <p>This is the user interface layer responsible for handling user interactions. It often includes web pages or user interfaces in desktop applications.</p> <p>Business Logic Layer</p> <p>Also known as the application layer, this layer contains the core logic and business rules of the application. It processes requests from the presentation layer and communicates with the data access layer.</p> <p>Data Access Layer</p> <p>This layer is responsible for interacting with the database or data storage. It performs tasks such as data retrieval, storage, and manipulation.</p> <p>Database Layer</p> <p>This layer involves the actual database system where data is stored and managed.</p> <p>However, it is important to note that the layered architecture style is associated with certain <code>architectural anti-patterns</code>, such as the <code>architecture by implication anti-pattern</code> and the <code>accidental architecture anti-pattern</code>. These issues can arise when the development process <code>lacks proper planning or when the architecture is not explicitly defined</code>.</p> <p>In practical terms, <code>if developers or architects are uncertain about the architecture style</code> being employed, or if an Agile development team initiates coding without a clear architectural plan, <code>it is highly probable that they are adopting the layered architecture style</code>.</p>"},{"location":"arch_styles/layered_arch/#topology","title":"Topology","text":"<p>The layered architecture style <code>organizes components into distinct horizontal layers, each with a specific function within the application</code>. While the <code>number and types of layers can vary</code>, the typical layered architecture comprises four fundamental layers: presentation, business, persistence, and database. <code>Each layer assumes a defined role and responsibility, abstracting the necessary tasks to fulfill specific business requests</code>.</p> <p>Example</p> <p>For instance, the <code>presentation layer focuses on displaying information in a specific format, without requiring knowledge about data retrieval processes</code>. This segregation of concerns allows for the <code>establishment of clear role and responsibility models within the architecture</code>. Components within a particular layer are confined to tasks pertinent to that layer, ensuring a focused and modular approach to development.</p> <p>However, this structured separation in the layered architecture <code>can potentially lead to a decrease in overall agility, hampering the ability to swiftly adapt to changes</code>. As a technically partitioned architecture, i<code>t groups components by their technical roles rather than by business domains</code>. Consequently, a <code>specific business domain</code>, like \"customer,\" <code>spans various layers within the architecture, making it challenging to implement changes within that domain</code>. This characteristic makes it less suitable for the effective implementation of a domain-driven design approach.</p>"},{"location":"arch_styles/layered_arch/#deployment","title":"Deployment","text":"<p>The <code>deployment of the layered architecture style can take several physical layering forms, resulting in distinct topology variants.</code></p> <p>The First Variant</p> <p>The <code>presentation, business, and persistence layers into a singular deployment unit</code>. Simultaneously, the database layer remains external, often as a distinct physical database or filesystem.</p> <p>The Second Variant</p> <p>The <code>presentation layer is physically separated into its deployment unit</code>, while the <code>business and persistence layers are combined into a second deployment unit</code>. As in the first variant, the <code>database layer is typically segregated into an external database or filesystem</code>.</p> <p>The Third Variant</p> <p>The third variant amalgamates <code>all four standard layers, including the database layer, into a single deployment unit</code>. This approach proves beneficial for smaller applications, especially those utilizing either an internally embedded database or an in-memory database.</p> <p><code>The choice of a deployment variant should align with the specific requirements of the application</code>, including considerations related to application size, performance demands, and the necessity for scalability and flexibility.</p>"},{"location":"arch_styles/layered_arch/#layers","title":"Layers","text":""},{"location":"arch_styles/layered_arch/#layers-of-isolation","title":"Layers of Isolation","text":"<p>In the <code>context of the layered architecture style, layers can be classified as either closed or open</code>.</p> <p>Closed Layers</p> <p>A closed layer mandates that a request <code>must pass through each layer in a sequential top-down manner</code>, without the ability to skip any intermediary layers.</p> <p>Open Layers</p> <p>In contrast with Closed Layers, an <code>open layer allows a request to bypass other layers</code>, potentially leading to a more flexible but complex system.</p> <p>Determining whether open or closed layers are preferable depends on the concept of <code>layers of isolation</code>. This concept <code>emphasizes that modifications in one layer typically do not affect components in other layers</code>, provided that the contracts between the layers remain unchanged. This independence among layers minimizes the interdependencies between them, facilitating maintainability and adaptability.</p> <p>However, <code>to ensure effective layers of isolation, layers involved in the primary flow of requests should be closed</code>. Allowing direct access from the presentation layer to the persistence layer, for instance, can tightly couple the application's components, making the architecture rigid and difficult to modify.</p> <p>The layers of isolation concept also <code>enable seamless layer replacements without impacting other layers, assuming well-defined contracts</code> and the utilization of appropriate design patterns. Leveraging this concept in the layered architecture style enables the replacement of outdated components, such as migrating from JavaServer Faces (JSF) to React.js for the presentation layer, without necessitating changes in other parts of the application.</p>"},{"location":"arch_styles/layered_arch/#adding-layers","title":"Adding Layers","text":"<p>While closed layers promote effective isolation and encapsulation of change within the architecture, <code>there are instances where incorporating open layers can be advantageous</code>. For instance, a layer with <code>common functionalities</code> like date and string utility classes, logging classes, and similar utilities might benefit from being an <code>open layer</code>. <code>This approach facilitates convenient accessibility across various parts of the architecture</code>.</p> <p><code>The concept of open and closed layers plays a critical role in defining the relationship between architecture layers and the flow of requests</code>. It offers developers essential insights into the access restrictions of different layers within the architecture. <code>Properly documenting and communicating the status of open and closed layers</code>, along with the rationale behind these decisions, <code>is crucial</code>. Neglecting to provide clear documentation or communication about the openness or closedness of layers can result in tightly coupled and fragile architectures that are challenging to test, maintain, and deploy.</p> <p><code>By strategically incorporating open layers to accommodate common functionalities and by clearly delineating the access restrictions within the architecture</code>, developers can create a more <code>flexible and adaptable system while maintaining the benefits of layered isolation</code>.</p>"},{"location":"arch_styles/layered_arch/#other-considerations","title":"Other Considerations","text":"<p><code>The layered architecture serves as a solid foundational structure for many applications, especially in cases where the definitive architecture style remains undetermined during the initial development phase</code>. However, an important consideration when implementing the layered architecture is the <code>potential risk of encountering the architecture sinkhole anti-pattern</code>.</p>"},{"location":"arch_styles/layered_arch/#sinkhole-anti-pattern","title":"Sinkhole Anti-Pattern","text":"<p>This anti-pattern occurs when <code>requests are transferred across different layers in a simplistic pass-through manner, devoid of any meaningful business logic within each layer</code>. This practice results in <code>unnecessary object instantiation and processing</code>, adversely impacting memory consumption and overall system performance.</p> Example <p>Presentation layer responds to a user request to fetch basic customer data, the request is successively passed through the business layer, the rules layer, the persistence layer, and eventually to the database layer <code>without any data manipulation, aggregation, or rule application taking place</code>.</p> <p>While it's common for certain scenarios in a layered architecture to exhibit elements of the architecture sinkhole anti-pattern, <code>it is crucial to evaluate the proportion of requests that fall into this category</code>. Adhering to the 80-20 rule is often advisable. For instance, if <code>only 20 percent of the requests</code> demonstrate sinkhole characteristics, it might be deemed <code>acceptable</code>. However, if the majority, or <code>80 percent</code>, of the requests conform to this pattern, <code>it serves as a strong indicator that the layered architecture may not be the most appropriate choice for the specific problem domain at hand</code>.</p>"},{"location":"arch_styles/layered_arch/#why-use-this-architecture-style","title":"Why Use This Architecture Style","text":"<p>The layered architecture style serves as an good choice for small, straightforward applications or websites. <code>Its simplicity and developer familiarity make it a preferred option, especially in scenarios with tight budgetary and time constraints</code>. Due to its minimalistic approach, the <code>layered architecture style represents one of the most cost-effective options, facilitating smoother and quicker development processes for smaller-scale applications</code>. Moreover, it is p<code>articularly beneficial in situations where architects are still in the process of analyzing business requirements and are uncertain</code> about the most suitable architecture style.</p> <p>However, <code>as applications built using the layered architecture style begin to scale, certain attributes such as maintainability, agility, testability, and deployability may gradually decline</code>.</p>"},{"location":"arch_styles/microkernel_arch/","title":"Microkernel Architecture Style","text":"<p>The concept of the microkernel architecture, often termed the <code>plug-in architecture</code>, originated many years ago and <code>continues to be a prominent feature in modern software design</code>. This style particularly <code>suits product-based applications</code>, which are typically distributed as a single, comprehensive deployment, <code>installed at the customer's location as a third-party product</code>. Its utility isn't limited to products, as it also finds extensive use in custom-built business applications.</p>"},{"location":"arch_styles/microkernel_arch/#topology","title":"Topology","text":"<p>Microkernel architecture is a <code>basic two-components monolithic structure</code>. It consists of a <code>core system and plug-in components</code>. This setup divides the <code>application logic between the autonomous plug-ins</code> and the <code>fundamental core system</code>, allowing for flexibility, customization, and segregation of application features and specific processing logic.</p> <p></p> <p>Basic components of the microkernel architecture style from Fundamentals of Software Architecture.</p> <p>The <code>core system assumes the responsibility of supplying necessary data to each plug-in</code>. Decoupling is the main rationale behind this strategy. <code>Any modifications to the database should only affect the core system</code>, not the plug-in components. However, <code>plug-ins can maintain their own distinct data stores accessible solely to their respective plug-ins</code>.</p> <p></p> <p>Plug-in components can own their own data store from Fundamentals of Software Architecture.</p>"},{"location":"arch_styles/microkernel_arch/#core-system","title":"Core System","text":"<p><code>The core system is the essential functionality needed to operate the system</code>. For instance, <code>an IDE it's the basic text editor</code> enabling actions like opening, editing, and saving files. It's <code>only when plug-ins are added that it becomes a fully functional product</code>.</p> <p>Another definition of the core system is the <code>straightforward path through the application</code>, without custom processing. <code>Transferring complex functions to plug-ins simplifies the core system, making it more extensible, maintainable, and testable</code>.</p> <p>Depending on the application's scale, the <code>core system can be structured as a layered architecture or a modular monolith</code>. Additionally, it can be split into separately deployed domain services, each containing domain-specific plug-in components.</p> Example <p></p> <p>Variations of the microkernel architecture core system from Fundamentals of  Software Architecture.</p> <p></p> <p>User interface variants from Fundamentals of Software Architecture.</p>"},{"location":"arch_styles/microkernel_arch/#plug-in-components","title":"Plug-In Components","text":"<p><code>Plug-in components are self-contained units housing specific functionalities, additional features, and customized code designed to amplify or extend the core system</code>. They also serve to <code>isolate volatile code</code>, enhancing the application's maintainability and testability. <code>The goal is to ensure plug-in components remain independent without interdependencies</code>.</p> <p>These plug-in components can be either <code>compile-based or runtime-based</code>. <code>Runtime plug-ins can be added or removed without redeploying the core system or other plug-ins</code>. In contrast, <code>compile-based</code> plug-ins are more straightforward to manage but necessitate <code>redeployment of the entire monolithic application when modified, added, or removed</code>.</p> <p><code>Communication between the plug-in components and the core system typically occurs through point-to-point connections</code>. This connection, often represented as a <code>pipe</code>, is generally a method invocation or function call to the entry-point class of the plug-in component. While plug-in components <code>primarily engage in point-to-point communication</code> with the core system, <code>there are alternatives such as using REST or messaging to invoke plug-in functionality</code>.</p> <p>In this scenario, <code>each plug-in functions as a standalone service</code>, or even a microservice implemented within a container. Although this approach may seem conducive to scalability, it's important to note that this setup <code>remains a single architecture quantum due to the monolithic core system. Consequently, every request must first pass through the core system to access the plug-in service</code>.</p> Example <p></p> <p>Remote plug-in access using REST from Fundamentals of  Software Architecture.</p>"},{"location":"arch_styles/microkernel_arch/#trade-offs","title":"Trade-Offs","text":"<p><code>Enabling remote plug-in access transforms the microkernel architecture into a distributed one</code>, which can pose challenges for implementing and deploying most third-party on-prem products. Additionally, it introduces increased complexity, higher costs, and complicates the overall deployment structure.</p> <p><code>Deciding whether to establish communication to plug-in components from the core system as point-to-point or remote should be based on specific requirements</code>, necessitating a thorough analysis of the trade-offs between the benefits and drawbacks of each approach.</p>"},{"location":"arch_styles/microkernel_arch/#registry-plug-in-components","title":"Registry Plug-In Components","text":"<p><code>For effective communication with plug-in modules, the core system requires knowledge of their availability and access methods</code>. One common approach is the utilization of a <code>plug-in registry</code>. This registry <code>holds comprehensive information about each plug-in module, including its name, data contract, and details about the remote access protocol if applicable</code>.</p> <p>For instance, a tax software plug-in designed to identify high-risk audit items may feature registry entries containing the service name (AuditChecker), data contract specifications (input and output data), and the contract format (XML).</p> <p>The registry can be as simple as an internal map structure owned by the core system, containing a key and a reference to the plug-in component. Alternatively, it can manifest as a sophisticated registry and discovery tool, integrated within the core system or externally deployed.</p>"},{"location":"arch_styles/microkernel_arch/#contracts","title":"Contracts","text":"<p><code>Contracts between plug-in components and the core system generally follow standard conventions within a domain of plug-in components</code>. These contracts <code>encompass behavior, input data, and output data returned from the plug-in component</code>. Situations involving <code>third-party plug-in development often involve custom contracts</code>, where the plug-in's <code>contract is beyond your control</code>. In such cases, it is customary to <code>establish an adapter between the plug-in contract and your standard contract</code>. This setup ensures that the core system does not require specialized code for each plug-in.</p> <p>Plug-in contracts can be implemented using various formats, such as XML, JSON, or object transmission between the plug-in and the core system.</p> Example <pre><code>class AssessmentOutput:\ndef __init__(self):\nself.assessmentReport = \"\"\nself.resell = False\nself.value = 0.0\nself.resellPrice = 0.0\nclass AssessmentPlugin:\ndef assess(self) -&gt; AssessmentOutput:\npass\ndef register(self) -&gt; str:\npass\ndef deregister(self) -&gt; str:\npass\n</code></pre>"},{"location":"arch_styles/microkernel_arch/#examples-and-use-cases","title":"Examples and Use Cases","text":"<p>Numerous software development and release tools are built using the microkernel architecture, including:</p> <ol> <li>Integrated Development Environments (IDEs) like Eclipse and Visual Code.</li> <li>Jira;</li> <li>Web browsers like Chrome and Firefox.</li> </ol> <p>This architecture also finds application in <code>extensive business systems</code>. For instance, consider the case of an insurance company handling insurance claims processing.</p> <p>Managing insurance claims involves intricate processes, with <code>varying regulations across different jurisdictions</code>. Many insurance claim applications rely on <code>complex rules engines to manage this complexity</code>. However, these rules engines can become intricate and challenging to maintain, often requiring extensive resources for even simple rule changes. <code>Implementing the microkernel architecture can effectively address these challenges</code>.</p> <p>In this setup, <code>the rules for each jurisdiction are stored in separate, standalone plug-in components</code>. These components can either be implemented as source code or specific instances of a rules engine accessible to the plug-in. <code>This allows for the seamless addition, removal, or modification of rules specific to a jurisdiction without affecting other parts of the system</code>. Moreover, it enables the system to add or remove new jurisdictions without causing disruptions elsewhere. In this context, the <code>core system primarily manages the standard processes for filing and processing claims, a component that undergoes infrequent changes</code>.</p>"},{"location":"arch_styles/microservices/","title":"Microservices Architecture Style","text":""},{"location":"arch_styles/microservices/#history","title":"History","text":"<p>Microservices differs in this regard\u2014it was namewd fairly early in its usage and popularized by a famous blog entry by Martin Fowler and James Lewis entitled Microservices, published in March 2014. They recognized many common characteristics in this relatively new architectural style and delineated them.</p> <p><code>A significant influence on microservices comes from domain-driven design (DDD)</code>, a logical design process for software projects. One key concept from DDD, known as bounded context, played a decisive role in inspiring microservices.</p>"},{"location":"arch_styles/microservices/#reuse-trade-offs-and-first-law-of-software-architecture","title":"Reuse, Trade-Offs and First Law of Software Architecture","text":"<p>While reuse holds clear advantages, it's crucial to remember the First Law of Software Architecture, which emphasizes trade-offs. <code>The negative trade-off of reuse is increased coupling</code>. When architects design a <code>system to prioritize reuse, they inherently introduce coupling, whether through inheritance or composition</code>.</p> <p><code>In scenarios where the architect's goal emphasizes high degrees of decoupling, microservices favor duplication over reuse</code>. The central objective of microservices is to achieve a high level of decoupling, aligning with the logical notion of bounded context from domain-driven design.</p>"},{"location":"arch_styles/microservices/#topology","title":"Topology","text":"<p>In the realm of microservices, <code>the architectural topology is characterized by the small size and single-purpose nature of each service</code>. Unlike other distributed architectures, <code>microservices envision services as standalone entities, each encapsulating all the essential components needed for independent operation, including databases and other dependencies</code>.</p> <p>Example</p> <p></p> <p>The topology of the microservices architecture style from Fundamentals of Software Architecture.</p>"},{"location":"arch_styles/microservices/#distributed","title":"Distributed","text":"<p>Microservices constitute a distributed architecture, <code>where each service operates in its independent process</code>. Initially tied to physical machines, <code>this concept has evolved to embrace virtual machines and containers</code>. The extensive decoupling of services in a distributed environment addresses common challenges in architectures featuring multitenant infrastructure, <code>offering operational advantages such as efficient resource utilization and improved isolation</code>.</p> <p><code>While this distributed approach brings benefits, it also introduces performance considerations</code>. <code>Network calls</code> inherently take longer than local method calls, and <code>security verification at each endpoint</code> adds processing time. Consequently, architects must carefully consider granularity when designing a system to mitigate these implications.</p> <p>One notable aspect of microservices is the <code>reluctance to employ transactions across service boundaries</code>. Seasoned architects emphasize the <code>importance of determining the appropriate granularity for services</code> as a key factor in achieving success within this architecture.</p>"},{"location":"arch_styles/microservices/#bounded-context","title":"Bounded Context","text":"<p><code>The bounded context concept embodies a decoupling strategy</code>. In the context of software development, when a developer defines a domain, <code>that domain includes many entities and behaviors reflected in artifacts such as code and database schemas</code>.</p> <p>Example</p> <p>An application might have a domain named <code>CatalogCheckout</code>, encompassing elements like catalog items, customers, and payment.</p> <p><code>In a traditional monolithic architecture, developers commonly share these concepts, creating reusable classes and interconnected databases</code>. In a bounded context, however, <code>internal components, like code and data schemas, are tightly coupled to accomplish their work but remain decoupled from anything outside the bounded context</code>, such as a database or class definition from another bounded context. This allows each context to define only what it requires without being influenced by other constituents.</p> <p><code>Microservices architecture revolves around the core concept of bounded context, where each service encapsulates a specific domain or workflow</code>. This approach aims to include everything essential for a service to operate independently within the application, <code>discouraging unnecessary coupling and emphasizing duplication over shared resources</code>.</p>"},{"location":"arch_styles/microservices/#granularity","title":"Granularity","text":"<p>Determining the <code>appropriate granularity for services</code> in microservices poses a common challenge for architects. <code>Oversimplifying by creating overly small services can lead to increased communication links between services, impacting overall system efficiency</code>. <code>Striking the right balance is crucial for achieving effective communication and collaboration among services</code>.</p> <p>Applications may have naturally expansive boundaries for certain segments, <code>acknowledging that certain business processes exhibit higher levels of coupling than others is essential</code>. Architects can navigate this challenge by adhering to guidelines that assist in identifying the most suitable boundaries for effective microservices implementation :</p> <p>Purpose</p> <p>Microservices should ideally <code>exhibit high functional cohesion, representing a distinct and significant behavior contributing to the overall application</code>.</p> <p>Transactions</p> <p><code>Minimizing reliance on transactions enhances the robustness of distributed architectures</code>.Bounded contexts are business workflows, and often <code>entities cooperating in transactions can guide architects in defining suitable service boundaries</code>.</p> <p>Choreography</p> <p>Architectures that balance domain isolation with communication requirements might benefit from <code>bundling services back into larger entities to mitigate communication overhead, in cases when multiple services require extensive communications</code>.</p> <p><code>Iterative refinement is essential for achieving optimal service design</code>. Architects rarely achieve the perfect granularity, data dependencies, and communication styles on the initial attempt. <code>Continuous iteration and refinement increase the likelihood of developing a well-tailored and efficient microservices architecture</code>.</p>"},{"location":"arch_styles/microservices/#data-isolation","title":"Data Isolation","text":"<p>Microservices necessitates a focus on data isolation, an aspect that distinguishes it from other architecture styles that rely on a single database for persistence. <code>In the pursuit of minimal coupling, microservices avoids shared schemas and databases functioning as integration points</code>.</p> <p>When determining service granularity, architects must be cautious of falling into the entity trap and <code>resist the temptation to simply model their services to resemble single entities in a database</code>.</p> <p><code>Unlike conventional practices of utilizing relational databases for consolidating values within a system to establish a single source of truth</code>, microservices, with its distributed nature, poses a challenge in maintaining this approach. Architects are tasked with <code>deciding how to address this issue: designating one domain as the source of truth for specific information and coordinating with it for value retrieval, or employing database replication or caching for information distribution</code>.</p> <p>While this level of data isolation may present challenges, it also opens avenues for <code>flexibility</code>. With teams no longer compelled to converge on a single database, <code>each service can opt for the most suitable tool</code> based on factors such as cost, storage type, and other considerations. In a highly decoupled system, teams enjoy the advantage of <code>adapting their choices without affecting other teams, as coupling to implementation details is prohibited</code>.</p>"},{"location":"arch_styles/microservices/#api-layer","title":"API Layer","text":"<p>In the microservices paradigm, diagrams often feature an <code>API layer positioned between the system's consumers</code> (user interfaces or calls from other systems), <code>although its inclusion is optional</code>. While the API layer serves various purposes, <code>it should not function as a mediator or orchestration tool</code> if architects intend to adhere to the fundamental philosophy of this architecture. According to this philosophy, <code>all significant logic within microservices should take place within a bounded context</code>, and introducing orchestration or similar logic in a mediator would violate this principle.</p> <p>This also illustrates the <code>difference between technical and domain partitioning in architecture</code>: architects typically use <code>mediators in technically partitioned architectures</code>, whereas <code>microservices is firmly domain partitioned</code>.</p>"},{"location":"arch_styles/microservices/#operational-reuse","title":"Operational Reuse","text":"<p>In the microservices paradigm, <code>where duplication is favored over coupling</code>, architects face the challenge of <code>handling operational concerns that traditionally benefit from coupling</code>, such as monitoring, logging, and circuit breakers. Unlike the traditional service-oriented architecture philosophy, which promotes reusing both domain and operational functionality, microservices endeavors to separate these two concerns.</p> <p>As teams build multiple microservices, they recognize <code>common elements that could benefit from a shared approach</code>. The sidecar pattern emerges as a solution to this challenge. <code>Operational concerns are encapsulated within each service as a distinct component</code>, owned either by individual teams or a centralized infrastructure team. <code>This sidecar component efficiently manages all operational aspects that teams find advantageous to couple together</code>. Consequently, when updates or upgrades are needed, the shared infrastructure team can seamlessly update the sidecar, ensuring that each microservice receives the new functionality.</p> <p><code>The sidecar pattern not only addresses the challenge of common operational concerns but also facilitates the creation of a</code> service mesh. This mesh allows for centralized control across the architecture for vital concerns like logging and monitoring. <code>The individual sidecar components connect to form a cohesive operational interface, creating a unified experience across all microservices</code>. Each microservice functions as a node within this mesh, offering a console for global control over operational coupling, including monitoring levels, logging, and other cross-cutting operational considerations.</p> <p><code>Service discovery plays a crucial role in achieving elasticity in microservices architectures</code>. Instead of directly invoking a single service, <code>requests are routed through a service discovery tool, which monitors request patterns and can scale or spin up new service instances as needed</code>. <code>Architects often integrate service discovery into the service mesh, making it an integral part of every microservice</code>. The API layer is frequently utilized to host service discovery, providing a centralized location for user interfaces or other calling systems to discover and create services in a flexible and consistent manner.</p>"},{"location":"arch_styles/microservices/#frontends","title":"Frontends","text":"<p>Microservices prioritize decoupling, <code>aiming to extend this separation to both backend and user interface concerns</code>. While the <code>original vision of microservices included the user interface as part of the bounded context</code> in alignment with Domain-Driven Design (DDD) principles, <code>practical considerations, particularly in web applications, have presented challenges to fully realizing this goal</code>. As a result, two predominant styles of user interfaces have emerged in microservices architectures.</p> <p>The first style involves a <code>monolithic frontend</code>, where a <code>single user interface interacts with the backend through the API layer</code> to fulfill user requests. This frontend can take various forms, such as a rich desktop application, mobile app, or web application. For instance, many modern web applications utilize JavaScript web frameworks to construct a unified user interface.</p> <p>The second option for user interfaces adopts <code>microfrontends, leveraging components at the user interface level to achieve a level of granularity and isolation in sync with the backend services</code>. In this approach, <code>each service emits its own user interface</code>, and the frontend coordinates with these emitted user interface components. This pattern allows teams to establish clear service boundaries from the user interface to the backend services, promoting unity within a single team across the entire domain.</p>"},{"location":"arch_styles/microservices/#communication","title":"Communication","text":"<p>In microservices, the <code>challenge of determining appropriate granularity impacts both data isolation and communication, influencing how services remain decoupled while still coordinating effectively</code>.</p> <p>At its core, architects must make a <code>fundamental decision regarding synchronous or asynchronous communication</code>. Synchronous communication entails the caller waiting for a response from the callee. Microservices architectures typically employ <code>protocol-aware heterogeneous interoperability</code>.</p> <p>Protocol-Aware, Heterogeneous and Interoperability</p> <p>Protocol-aware</p> <p>Because microservices lack a centralized integration hub to avoid operational coupling, <code>each service should understand how to call other services</code>. As a result, <code>architects often standardize on specific protocols for inter-service communication</code>, such as a level of REST, message queues, and so forth. This implies that services must be aware of (or discover) the protocol to use when calling other services.</p> <p>Heterogeneous</p> <p><code>Each service may be developed in a different technology stack</code>. Embracing heterogeneity signifies that microservices fully supports polyglot environments, where various services utilize different platforms.</p> <p>Interoperability</p> <p><code>Describing services calling one another</code>, interoperability in microservices aims to discourage transactional method calls while <code>promoting network-based communication</code>.</p> <p>For <code>asynchronous</code> communication, architects often leverage <code>events and messages</code>, resulting in an internal event-driven architecture. In microservices, the broker and mediator patterns manifest as choreography and orchestration.</p>"},{"location":"arch_styles/microservices/#choreography-and-orchestration","title":"Choreography and Orchestration","text":"<p><code>Choreography in microservices utilizes the communication style of a</code> broker event-driven architecture. Unlike architectures with a central coordinator, <code>choreography adheres to the bounded context philosophy</code>, promoting the implementation of decoupled events between services. In this approach, <code>each service independently calls others as needed, without relying on a central mediator</code>.</p> Choreography <p>Suppose a user requests details about a wish list, and the <code>CustomerWishList</code> service lacks essential information. In choreography, it would make a <code>direct call to CustomerDemographics to retrieve the missing data</code>, delivering the result back to the user.</p> <p></p> <p>Using choreography in microservices to manage coordination from Fundamentals of Software Architecture.</p> <p>Because microservices architectures <code>lacks a global mediator</code> like in some service-oriented architectures, <code>allow architects to create localized mediators when coordination across multiple services is necessary</code>. Developers can design a <code>service dedicated to coordinating specific calls, such as obtaining comprehensive customer information</code>. Users then interact with this mediator service, which, in turn, communicates with the required services.</p> Orchestration <p></p> <p>Using orchestration in microservices from Fundamentals of Software Architecture.</p> <p>The First Law of Software Architecture acknowledges that <code>neither choreography nor orchestration is flawless\u2014each comes with trade-offs</code>. In choreography, architects uphold the highly decoupled philosophy of the architecture, maximizing the benefits it offers. However, <code>handling common challenges like error management and coordination becomes more intricate in choreographed environments</code>.</p> <p>In scenarios involving complex workflows, <code>the initial service called may need to act as a mediator, coordinating interactions across a range of other services</code>. This pattern, known as the <code>front controller pattern</code>, transforms a nominally choreographed service into a more complex mediator. <code>The drawback lies in the increased complexity within the service</code>.</p> Complex Choreography <p></p> <p>Using choreography for a complex business process from Fundamentals of Software Architecture.</p> <p>On the other hand, <code>architects may opt for orchestration in handling intricate business processes</code>. <code>By constructing a mediator, architects manage the complexity and coordination required for the business workflow</code>. While this <code>introduces coupling between services</code>, it enables architects to concentrate coordination efforts into a single service, minimizing the impact on others. Often, <code>domain workflows inherently involve some level of coupling, challenging architects to represent that coupling in ways that align with both domain and architectural objectives</code>.</p> Complex Orchestration <p></p> <p>Using orchestration in microservices from Fundamentals of Software Architecture.</p>"},{"location":"arch_styles/microservices/#transactions-and-sagas","title":"Transactions and SAGAS","text":"<p>Architects in the realm of microservices <code>looks for extreme decoupling</code>, but they often grapple with the <code>challenge of coordinating transactions across services</code>. The same level of decoupling that characterizes the architecture, especially in terms of databases, <code>complicates achieving the atomicity that was once straightforward in monolithic applications</code>.</p> <p><code>Constructing transactions that span service boundaries contradicts the fundamental decoupling principle of microservices and introduces a form of dynamic connascence, the worst known connascence</code>, the connascence of value. The foremost advice for architects contemplating transactions across services is unequivocal: avoid it! Instead, address the granularity of components. Transaction boundaries often serve as a key indicator of service granularity.</p> <p>Danger</p> <p>The foremost advice for architects contemplating transactions across services is unequivocal: <code>avoid it!</code> Instead, <code>address the granularity of components.</code> Transaction boundaries often serve as a key indicator of service granularity.</p> <p>Tip</p> <p>Don\u2019t do transactions in microservices. <code>Fix granularity instead!</code></p> <p>For services that still demanding transactional coordination, <code>there are patterns available to manage transaction orchestration, with significant trade-offs</code>.</p> <p>One prevalent distributed transactional pattern in microservices is the saga pattern. In this approach, <code>a service assumes the role of a mediator, orchestrating multiple service calls and coordinating the transaction</code>. The mediator initiates each part of the transaction, logs success or failure, and manages the overall outcome. <code>If everything proceeds as planned, all values in the services and their associated databases update synchronously</code>.</p> Example <p></p> <p>The saga pattern in microservices architecture from Fundamentals of Software Architecture.</p> <p><code>In the event of an error, the mediator ensures that no part of the transaction succeeds if another part fails</code>. If the initial part succeeds but the subsequent part encounters a failure, the mediator <code>sends a request to all successful parts, instructing them to undo their previous actions</code>. This style of transactional coordination is known as a <code>compensating transaction framework</code>. Typically, developers implement this pattern by <code>placing each mediator-initiated request in a pending state until the overall success is signaled by the mediator</code>. However, this design <code>complexity intensifies when dealing with asynchronous requests</code>, especially if new requests depend on pending transactional states. It also results in <code>increased coordination traffic at the network level</code>.</p> Example <p></p> <p>Saga pattern compensating transactions for error conditions from Fundamentals of Software Architecture.</p> <p>An alternative implementation of a compensating transaction framework involves developers creating both <code>do</code> and <code>undo</code> operations <code>for each potentially transactional operation</code>. While this approach reduces coordination during transactions, <code>the undo operations tend to be considerably more complex</code> than their counterpart do operations, essentially doubling the effort required for design, implementation, and debugging.</p> <p>While architects can technically build transactional behavior across services, doing so <code>contradicts the core rationale behind choosing the microservices pattern</code>. While exceptions may arise, the overarching advice for architects is to use the saga pattern judiciously.</p> <p>Tip</p> <p>A few transactions across services may be necessary, but if they dominate the architecture, it indicates potential mistakes in the design!</p>"},{"location":"arch_styles/mono_distributed/","title":"Monolithic vs Distributed Architectures","text":"<p>There are <code>two primary categories</code>: monolithic and distributed architectures. These categories serve as a foundational distinction, even though it's important to note that <code>no classification is perfect</code>. <code>Distributed architectures, in particular, introduce a unique set of challenges that set them apart from monolithic architectures</code>. This classification offers a valuable way to differentiate between various architectural styles.</p>"},{"location":"arch_styles/mono_distributed/#monolithic-list","title":"Monolithic List","text":"<ol> <li>Layered Architecture</li> <li>Pipeline Architecture</li> <li>Microkernel Architecture</li> </ol>"},{"location":"arch_styles/mono_distributed/#distributed-list","title":"Distributed List","text":"<ol> <li>Service-based Architecture</li> <li>Event-driven Architecture</li> <li>Space-based Architecture</li> <li>Service-oriented Architecture</li> <li>Microservices Architecture</li> </ol>"},{"location":"arch_styles/mono_distributed/#fallacies-of-distributed-computing","title":"Fallacies of Distributed Computing","text":"<p>Distributed architectures <code>can be more</code> powerful in terms of performance, scalability, and availability than monolithic architecture styles, <code>but they come with trade-offs</code>. <code>Some common misconceptions, can lead to false assumptions in distributed systems</code>. Understanding these misconceptions is crucial in designing distributed architectures.</p>"},{"location":"arch_styles/mono_distributed/#the-network-is-reliable","title":"The Network Is Reliable","text":"<p><code>People often assume that networks are reliable, but they're not</code>. Even though networks have improved, they can still be unreliable. <code>This is critical in distributed architectures because they heavily depend on network communication</code>. Measures like timeouts and circuit breakers are used to manage this unpredictability, especially in systems like microservices. <code>The more a system relies on the network, the less reliable it can be</code>. Latency in any distributed architecture is not zero, yet most architects ignore this fallacy, insisting that they have fast networks.</p>"},{"location":"arch_styles/mono_distributed/#latency-is-zero","title":"Latency Is Zero","text":"<p><code>Local calls between components are faster than remote ones using protocols like REST, messaging, or RPC</code>. <code>Knowing the average round-trip latency for remote calls is crucial in distributed architectures</code>, especially microservices.</p> Calculating Latency <p>If the average latency is 100 milliseconds, chaining 10 service calls adds 1,000 milliseconds to a request. <code>However, it's not just the average latency that matters; the 95th to 99th percentile can significantly impact performance</code>. So, understanding these latencies is vital for architecting distributed systems.</p>"},{"location":"arch_styles/mono_distributed/#bandwidth-is-infinite","title":"Bandwidth Is Infinite","text":"<p>In monolithic architectures, <code>bandwidth is typically not a concern because processing within a monolith often requires little to no additional bandwidth</code>. However, in distributed systems, <code>communication between services can consumes significant bandwidth, which can lead to network slowdowns</code>.</p> <p>When a service needs to connect to other services to process requests, it consumes bandwidth. This can become problematic, especially if these requests occur frequently. This situation, known as <code>stamp coupling</code>, can have a significant impact on bandwidth usage. <code>To address stamp coupling in distributed architectures, there are several approaches you can consider</code>:</p> <ol> <li>Create private RESTful API endpoints.</li> <li>Use field selectors in the contract.</li> <li>Adopt GraphQL to decouple contracts.</li> <li>Combine value-driven contracts with consumer-driven contracts (CDCs).</li> <li>Leverage internal messaging endpoints.</li> </ol> <p>Tip</p> <p>No matter which approach you choose, <code>the key is to minimize the amount of data transferred between services or systems in a distributed architecture</code>. This is essential for addressing the fallacy of infinite bandwidth.</p>"},{"location":"arch_styles/mono_distributed/#the-network-is-secure","title":"The Network Is Secure","text":"<p>In the world of distributed computing, it's common for architects and developers to rely on tools like virtual private networks (VPNs), trusted networks, and firewalls, which can create a false sense of security. However, <code>it's crucial to remember that the network itself is not inherently secure</code>.</p> <p><code>Security becomes a much more complex challenge in distributed architectures</code>. In such systems, <code>every endpoint, associated with each distributed deployment unit, must be diligently secured to prevent unauthorized or malicious requests from reaching those services</code>. As you transition from a monolithic to a distributed architecture, the potential surface area for security threats and attacks increases significantly.</p> <p><code>Ensuring the security of every endpoint, even during interservice communication, is a demanding task</code>. This is one of the reasons why <code>synchronous</code>, highly-distributed architectures like microservices or service-based architecture often exhibit slower performance. The need to address security at every level introduces additional overhead and complexity.</p>"},{"location":"arch_styles/mono_distributed/#the-topology-never-changes","title":"The Topology Never Changes","text":"<p>This fallacy <code>assumes that the overall network structure</code>, including routers, hubs, switches, firewalls, and other network components, remains static and <code>never undergoes changes. However, in reality, network topologies can and do change</code>.</p> <p><code>Architects should recognize that network topologies are dynamic</code> and may evolve over time. <code>It's crucial for architects to maintain open communication with network administrators and operations teams to stay informed about any changes to the network infrastructure</code>. This awareness allows architects to adapt and make necessary adjustments to ensure the reliability and performance of distributed systems, minimizing unwelcome surprises.</p>"},{"location":"arch_styles/mono_distributed/#there-is-only-one-administrator","title":"There Is Only One Administrator","text":"<p>Architects often make the <code>mistake of assuming they only need to collaborate and communicate with a single administrator when dealing with network issues</code>. This fallacy <code>highlights the complexity of distributed architecture and the need for extensive coordination</code>.</p> <p><code>In distributed architectures, effective communication and collaboration with multiple administrators are essential</code>. Unlike monolithic applications, where a single deployment unit simplifies administration, distributed systems require architects to engage with various network administrators to ensure everything functions correctly.</p>"},{"location":"arch_styles/mono_distributed/#transport-cost-is-zero","title":"Transport Cost Is Zero","text":"<p>The term <code>transport cost</code> in this context doesn't refer to how quickly data travels, but to the <code>actual expenses incurred when making what seems like a simple RESTful call.</code> Architects often mistakenly assume that the existing infrastructure is enough for such calls or for breaking down a monolithic application. However, this isn't usually the case.</p> <p><code>Distributed architectures typically come with significantly higher expenses compared to monolithic ones</code>. This increase in cost is primarily due to the need for extra hardware, servers, gateways, firewalls, the creation of new subnets, proxies, and other resources.</p> <p>When architects dive into <code>designing a distributed architecture, it's essential to thoroughly assess the current server and network infrastructure</code>. This assessment should consider factors like capacity, bandwidth, latency, and security zones. By doing this, architects can avoid being caught off guard by unexpected costs and plan more effectively.</p>"},{"location":"arch_styles/mono_distributed/#the-network-is-homogeneous","title":"The Network Is Homogeneous","text":"<p>Many architects and developers often assume that networks are homogeneous, consisting of hardware from a single vendor. In reality, <code>most companies have a mix of network hardware vendors in their infrastructure, and sometimes, even more than that</code>. The importance of this fallacy lies in the fact that <code>not all of these diverse hardware vendors seamlessly cooperate with one another</code>. While most components work together, questions arise about the seamless integration of Juniper hardware with Cisco hardware, for instance.</p> <p><code>While networking standards have progressed over the years, reducing this problem, the fact remains that not all scenarios, loads, and circumstances have been thoroughly tested</code>. Consequently, network packets can occasionally get lost, causing issues.</p>"},{"location":"arch_styles/mono_distributed/#references","title":"References","text":"<ul> <li>Fundamentals of Software Architecture</li> <li>The 95th and 99th percentiles are the most crucial application metrics</li> <li>What are 99 percentile and 95 percentile?</li> </ul>"},{"location":"arch_styles/orchestration_arch/","title":"Orchestration-Driven Service-Oriented Architecture","text":"<p>Danger</p> <p>This architecture style <code>represents an era-specific architectural style</code> influenced by external forces and organizational philosophies. Despite its logical foundation, <code>this architecture faced challenges that ultimately led to its downfall. It serves as a notable example of how a seemingly rational organizational idea can impede crucial aspects of the development process</code>.</p>"},{"location":"arch_styles/orchestration_arch/#history-and-philosophy","title":"History and Philosophy","text":"<p>In the late 1990s, the Orchestration-Driven Service-Oriented Architecture emerged as enterprises were rapidly expanding, necessitating sophisticated IT solutions. During this era, <code>companies faced challenges related to limited and expensive computing resources, prompting the adoption of distributed architectures for their scalability benefits</code>. The prevailing constraints were driven by factors such as the cost of operating systems and complex licensing schemes for commercial database servers.</p> <p><code>As a result, architects were compelled to maximize reuse</code>. The dominant philosophy underlying this architecture was centered on <code>achieving extensive reuse in all forms, with far-reaching consequences</code>.</p>"},{"location":"arch_styles/orchestration_arch/#topology","title":"Topology","text":"<p>The topology varied among implementations, but the overarching concept involved <code>establishing a taxonomy of services within the architecture, with each layer assigned specific responsibilities</code>.</p> <p>This style of architecture is inherently <code>distributed</code>, and the precise delineation of boundaries varied depending on the organization's specific requirements and structure.</p> <p>Example</p> <p></p> <p>Topology of orchestration-driven service-oriented architecture from Fundamentals of Software Architecture.</p>"},{"location":"arch_styles/orchestration_arch/#taxonomy","title":"Taxonomy","text":"<p><code>The services played a crucial role in this architecture centered around enterprise-level reuse</code>. Many large companies were annoyed at how much they had to continue to rewrite software. The various layers in this taxonomy were designed to support this objective.</p>"},{"location":"arch_styles/orchestration_arch/#business-servicess","title":"Business Servicess","text":"<p>Situated at the <code>top of the architecture</code>, business services <code>served as the entry point and encapsulated domain-specific behavior</code>. Examples like ExecuteTrade or PlaceOrder represented essential business activities. <code>These service definitions, often crafted by business users, contained input, output, and schema information but no actual code</code>.</p>"},{"location":"arch_styles/orchestration_arch/#enterprise-services","title":"Enterprise Services","text":"<p>Found beneath business services, <code>enterprise services housed fine-grained, shared implementations</code>. <code>Development teams focused on creating atomic behavior around specific business domains, such as CreateCustomer or CalculateQuote</code>. <code>These services acted as the foundational building blocks for the broader business services, connected through an orchestration engine</code>. The goal was to foster reuse by developing finely tuned enterprise services that could be leveraged across various business workflows.</p> <p>However, the <code>dynamic nature of the business landscape posed challenges to achieving complete stability</code>. Markets, technological advancements, and other factors complicated efforts to establish long-term stability in the software world.</p>"},{"location":"arch_styles/orchestration_arch/#application-services","title":"Application Services","text":"<p><code>Recognizing that not all services required the same level of granularity or reuse, application services were introduced</code>. These were one-off, <code>single-implementation services tailored to specific application needs</code>. For instance, an application might need a geo-location service without the organization investing in making it reusable. Application services were typically owned by a single application team, addressing specific requirements without the expectation of broader reuse.</p>"},{"location":"arch_styles/orchestration_arch/#infrastructure-services","title":"Infrastructure Services","text":"<p>Handling operational concerns like <code>monitoring, logging, authentication, and authorization</code>, infrastructure services constituted the bottom layer. These services provided concrete implementations and were owned by a shared infrastructure team working closely with operations to ensure the smooth functioning of the overall system.</p>"},{"location":"arch_styles/orchestration_arch/#orchestration-engine","title":"Orchestration Engine","text":"<p><code>At the heart of the Orchestration-Driven Service-Oriented Architecture lies the orchestration engine</code>. This pivotal component <code>intricately threads together the implementations of business services</code> through orchestration, encompassing features such as transactional coordination and message transformation.  In contrast to microservices architectures, where each service might maintain its database, <code>this architecture typically relies on a single relational database or a few databases</code>. As a result, <code>transactional behavior is declaratively managed within the orchestration engine rather than in individual databases</code>.</p> <p>The orchestration engine plays a pivotal role in <code>defining the relationships between business and enterprise services</code>, determining their alignment, and establishing transaction boundaries. It also operates as an integration hub, facilitating the seamless integration of custom code with packaged and legacy software systems.</p> <p>Being the central element of the architecture, <code>the team of integration architects responsible for the orchestration engine tends to emerge as a potent political force within the organization</code>, often evolving into a bureaucratic bottleneck, in line with Conway's law predictions.</p> <p>While the notion of off-loading transaction behavior to an orchestration tool seemed promising, practical implementation proved to be challenging. <code>Determining the optimal granularity of transactions became increasingly intricate</code>. While constructing a few services encapsulated in a distributed transaction is feasible, <code>the architecture's complexity heightens as developers grapple with defining appropriate transaction boundaries between services</code>.</p>"},{"location":"arch_styles/orchestration_arch/#message-flow","title":"Message Flow","text":"<p>In this architecture, all requests traverse the orchestration engine, serving as the locus of logic. Consequently, the message flow is directed through the engine even for internal calls.</p> <p>Example</p> <p>The <code>CreateQuote</code> business-level service initiates a call to the service bus, defining the workflow involving calls to <code>CreateCustomer</code> and <code>CalculateQuote</code>. Each of these, in turn, encompasses calls to application services. The service bus acts as the intermediary for all calls, functioning both as an integration hub and an orchestration engine.</p> <p></p> <p>Message flow with service-oriented architecture from Fundamentals of Software Architecture.</p>"},{"location":"arch_styles/orchestration_arch/#reuse-and-coupling-problem","title":"Reuse and Coupling Problem","text":"<p>A central objective of this architecture is <code>achieving reuse at the service level, aiming to gradually construct business behavior for incremental reuse over time</code>. Architects were encouraged to actively seek opportunities for reuse in this architecture. However, the realization of negative trade-offs unfolded slowly. <code>Building a system primarily around reuse resulted in significant coupling between components\u2014a consequence of consolidating behavior into a single location</code>. The impracticality of designing an architecture overly focused on technical partitioning became a stark revelation, despite its alignment with separation and reuse philosophies.</p> <p><code>Domain concepts</code>, such as CatalogCheckout, <code>suffered from being thinly spread across the architecture</code>, leading to a practical nightmare. Developers found themselves engaged in tasks like \"add a new address line to CatalogCheckout,\" which, in a service-oriented architecture, <code>could involve numerous services across various tiers and changes to a single database schema</code>. If the existing enterprise services lacked the correct transactional granularity, <code>developers faced the dilemma of either altering their design or constructing a new, nearly identical service, undermining the concept of reuse</code>.</p> <p>Example</p> <p>Consider a scenario with distinct divisions within an insurance company:</p> <ol> <li>Auto and Homeowners Insurance Division</li> <li>Life Insurance Division</li> <li>Commercial Insurance Division</li> <li>Disability Insurance Division</li> <li>Casualty Insurance Division</li> <li>Trave Insurance Division</li> </ol> <p>An architect identifies that <code>each division involves a concept of Customer</code>. The service-oriented architecture strategy suggests extracting customer elements into a reusable service and letting the original services reference the canonical <code>Customer service</code>. However, <code>any change to the Customer service has a ripple effect on all other services, introducing risk to the change process</code>. Consequently, architects grappled with making incremental changes, leading to significant ripple effects, necessitating coordinated deployments, holistic testing, and other impediments to engineering efficiency.</p> <p>To support a unified Customer service, <code>it must encompass all details known about customers</code>. For instance, auto insurance may require driver's license details, which pertain to the person rather than the vehicle. Consequently, the Customer service would need to include details about driver's licenses that the disability insurance division finds irrelevant. This challenge exemplifies the intricate balance between achieving reuse and managing coupling within the architecture.</p>"},{"location":"arch_styles/pipeline_arch/","title":"Pipeline Architecture Style","text":"<p>Also known as the pipes and filters architecture. As soon as developers and architects decided to split functionality into discrete parts, this pattern followed. Most developers know this architecture as this underlying principle behind Unix terminal shell languages, such as Bash and Zsh.</p> <p>Developers in many functional programming languages will see parallels between language constructs and elements of this architecture. In fact, many tools that utilize the MapReduce programming model follow this basic topology.</p>"},{"location":"arch_styles/pipeline_arch/#topology","title":"Topology","text":"<p>The pipeline architecture style comprises two fundamental components: <code>pipes and filters, each playing a specific role in the communication flow</code>. The unidirectional nature of pipes and filters within the p<code>ipeline architecture promotes a design that fosters compositional reuse</code>. Many developers have discovered this ability using shells.</p> <p></p> <p>Basic topology for pipeline architecture from Fundamentals of Software Architecture.</p>"},{"location":"arch_styles/pipeline_arch/#pipes","title":"Pipes","text":"<p><code>Pipes works as communication channels connecting the filters</code>. Typically, each pipe is unidirectional and establishes a point-to-point communication rather than broadcast, <code>prioritizing performance</code>. <code>It accepts input from a singular source and always directs the output to another</code>. While the data format can vary, architects often favor smaller data packets to ensure high performance within the pipeline.</p>"},{"location":"arch_styles/pipeline_arch/#filters","title":"Filters","text":"<p><code>Filters operate as self-contained entities, independent of other filters, and generally remain stateless</code>. It is crucial for <code>each filter to be dedicated to a specific task</code>. Complex tasks should be managed through a sequence of filters rather than a single one.</p> <p>The pipeline architecture style involves four types of filters:</p> <p>Producer</p> <p>Serves as the <code>initial stage of the process</code>, focusing on outbound operations only, and is sometimes referred to as the source.</p> <p>Transformer</p> <p><code>Accepts input, possibly conducts transformations on some or all of the data, and then directs it to the outbound pipe</code>. This function is comparable to the <code>map</code> feature in functional programming.</p> <p>Tester</p> <p><code>Accepts input, verifies one or more criteria, and optionally generates output based on the test</code>. This bears similarity to the <code>reduce</code> operation in functional programming.</p> <p>Consumer</p> <p><code>Represents the end point for the pipeline flow</code>. Consumers <code>often persist the final results of the pipeline process</code> to a database or display the outcomes on a user interface screen.</p>"},{"location":"arch_styles/pipeline_arch/#example","title":"Example","text":"<p>The pipeline architecture pattern is <code>prevalent</code> in various applications, <code>particularly those involved in straightforward, one-way processing</code>. ETL tools (extract, transform, and load) also leverage this architecture for efficient data flow and modification between databases or data sources.</p> <p>To exemplify the practical application of the pipeline architecture, consider the following scenario: <code>service telemetry information is streamed from multiple services to Apache Kafka</code>.  Observe the <code>utilization of the pipeline architecture style to handle diverse data types streamed</code> to Kafka.</p> <p></p> <p>Pipeline architecture example from Fundamentals of Software Architecture.</p> <p>Service Info Capture Filter (Producer)</p> <p>The Service Info Capture filter <code>subscribes to the Kafka topic and receives service information</code>. It then <code>forwards this data to the Duration Filter</code>. This filter <code>focuses solely on establishing a connection with a Kafka topic and receiving streaming data</code>.</p> <p>Duration Filter (Tester)</p> <p>The Duration Filter <code>checks if the data is about the service request duration</code>. <code>If it is, the data goes to the Duration Calculator</code>, and if not, it's sent to the Uptime Filter.</p> <p>Uptime Filter (Tester)</p> <p>The Uptime Filter <code>verifies if the data is about uptime metrics</code>. If it's not, the pipeline ends. <code>If it is, the data goes to the Uptime Calculator</code>.</p> <p>Duration and Uptime Calculator (Transformer)</p> <p>The Duration Calculator and Uptime Calculator <code>transmit the modified data by them to the Database Output consumer</code></p> <p>Database Output (Consumer)</p> <p>Stores the data in a MongoDB database.</p>"},{"location":"arch_styles/service_based_arch/","title":"Service-Base Architecture Style","text":"<p>Service-based architecture represents a <code>hybrid approach that combines elements of the microservices architecture style</code>. This pragmatic architectural style is known for its flexibility, making it a popular choice for various business applications. <code>Despite being a distributed architecture, it offers a balance between complexity and cost</code> when compared to more intricate distributed styles like microservices or event-driven architecture, making it a very popular choice for many business-related applications.</p>"},{"location":"arch_styles/service_based_arch/#topology","title":"Topology","text":"<p><code>The structure of service-based architecture is like a distributed system with different layers</code>. It includes a user interface that's deployed separately, bigger independent services, and a central database that holds everything together.</p> <p>In this style, the <code>services, which are like big chunks of the application, are called domain services. These services operate autonomously and are separately deployed. They share one big database</code>. There are usually 4 to 12 of these services in one application.</p> <p></p> <p>Basic topology of the service-based architecture style Fundamentals of Software Architecture.</p> <p>While a service-based architecture <code>usually maintains only a single instance of each domain service, multiple instances can exist</code> based on scalability, fault tolerance, and throughput requirements. <code>Multiple instances of a service necessitate load-balancing capabilities between the user interface and the domain service</code> to ensure the interface connects to a healthy and available service instance.</p> <p><code>Services are accessed remotely from a user interface through different ways like REST, messaging, or  remote procedure call (RPC)</code>. While an API layer with a proxy or gateway can be employed to access services, in most cases, the user interface interacts directly with the services.</p> <p><code>One important thing here is that all these services use the same database</code>. This means they can utilize SQL queries and joins akin to traditional monolithic layered architectures. Given the limited number of services, <code>database connections typically pose no issues in service-based architecture. However, database alterations can present challenges</code>.</p>"},{"location":"arch_styles/service_based_arch/#topology-variants","title":"Topology Variants","text":"<p>Within the service-based architecture style, various topology variants exist, making it one of the most adaptable styles.</p> Broken User Interface <p></p> <p>User interface variants from Fundamentals of Software Architecture.</p> Multiple Databases <p>Dividing a single monolithic database into <code>separate databases, sometimes even establishing domain-specific databases that match each domain service</code>, similar to how it's done in microservices. <code>The key here is to ensure that each separate database doesn't contain data needed by another domain service. This approach prevents the need for communication between domain services (something to avoid in service-based architecture) and avoids duplicating data across databases</code>.</p> <p></p> <p>Database variants from Fundamentals of Software Architecture.</p> API Layer <p>Another possibility is to introduce an <code>API layer, comprising a reverse proxy or gateway between the user interface and services</code>. This practice is <code>beneficial when exposing domain service functions to external systems or consolidating shared cross-cutting concerns</code>, moving them outside the user interface. Such concerns might include managing metrics, security, auditing requirements, and service discovery.</p> <p></p> <p>Adding an API layer between the user interface and domain services from Fundamentals of Software Architecture.</p>"},{"location":"arch_styles/service_based_arch/#service-and-granularity","title":"Service and Granularity","text":"<p><code>In a service-based architecture, domain services are generally designed with a coarse-grained approach</code>. Typically, each domain service includes an API facade layer, a business layer, and a persistence layer. An alternative design approach involves dividing each domain service into sub-domains, similar to the modular monolith architecture style.</p> Coarse-grained approach vs Fine-grained approach <p>In software architecture, a coarse-grained approach refers to the use of larger, more encompassing components or services that handle multiple tasks or operations as a single unit. On the other hand, a fine-grained approach involves the use of smaller, more specialized components or services, each responsible for specific and often singular tasks or operations.</p> <p><code>Irrespective of the design, every domain service must incorporate an API access facade that interacts with the user interface, managing the execution of various business functionalities</code>.</p> <p>Example</p> <p>For example, within the OrderService domain service, the API access facade orchestrates a business request, such as placing an order, processing payments, and updating product inventory for each item ordered. <code>This orchestration, which involves several tasks within a single service, differs from the orchestration of numerous distinct remote services in the microservices architecture style</code>.</p> <p><code>Due to their coarse-grained nature, domain services in a service-based architecture rely on regular ACID within a single service</code>. In contrast, highly distributed architectures like microservices, with their <code>fine-grained services, utilize a distributed transaction technique known as BASE transactions</code>.</p> <p>BASE transactions x ACID transactions</p> <p>These <code>BASE transactions (basic availability, soft state, eventual consistency) prioritize eventual consistency over strict database integrity</code>, distinguishing them from <code>ACID transactions (atomicity, consistency, isolation, durability) database transactions to maintain database integrity</code> in a service-based architecture.</p> <p>This disparity highlights a <code>key difference between internal class-level orchestration and external service orchestration, emphasizing the divergence in granularity between service-based architecture and microservices</code>.</p> <p>Although <code>coarse-grained domain services ensure robust data integrity and consistency</code>, they involve trade-offs. <code>Implementing changes to a functionality in service-based architecture necessitates testing the entire service, while in microservices, it only affects a small service without impacting others</code>.</p>"},{"location":"arch_styles/service_based_arch/#database-partitioning","title":"Database Partitioning","text":"<p>In a service-based architecture, <code>services often share a single/monolithic database</code>, primarily due to the small number of services within an application. <code>This database coupling, can bring challenges, especially concerning database table schema modifications</code>. Improper schema changes can potentially impact every service, rendering <code>database alterations costly in terms of effort and coordination</code>.</p> <p><code>The shared class files representing database table schemas (referred to as entity objects) typically reside in a custom shared library used by all domain services</code>. However, <code>employing a single shared library of entity objects can be less effective in this context</code>.</p> <p>The problem with single shared library</p> <p>Any alterations to the database table structures necessitate changes to the shared library, demanding <code>redeployment across all services, regardless of their direct use of the modified table</code>. While shared library versioning can aid in managing this issue, comprehending the actual impact on services without detailed analysis remains challenging.</p> <p><code>A practical solution to mitigate the effects of database changes involves logically partitioning the database and reflecting this partitioning through federated shared libraries</code>.</p> <p>Using partitioning database and libraries</p> <p>For instance, logical partitioning can be executed by <code>segmenting the database into distinct domains (such as common, customer, invoicing, order, and tracking), with corresponding shared libraries matching these partitions</code>. Employing this technique <code>ensures that changes made to a specific table within a particular domain only affect services associated with that partition</code>. <code>It's also possible to have a common domain with a common shared library used by all services</code>. <code>These tables are shared across all services</code>, and any changes to these tables require coordination among all services accessing the shared database.</p> <p></p> <p>Using multiple shared libraries for database entity objects from Fundamentals of Software Architecture.</p>"},{"location":"arch_styles/space_based_arch/","title":"Space-Based Architecture Style","text":"<p>The space-based architecture style is crafted to tackle <code>challenges related to high scalability, elasticity, and concurrent user demands</code>. <code>It proves beneficial for applications dealing with variable and unpredictable concurrent user volumes</code>. Architecturally addressing extreme scalability issues is often more effective than attempting to scale out a database or retrofit caching technologies into a non-scalable architecture.</p> <p>In high-volume applications with significant concurrent user loads, the <code>database typically becomes the ultimate bottleneck, limiting the number of transactions processed concurrently</code>. Despite the assistance of various caching technologies and database scaling products, scaling out a conventional application for extreme loads remains a challenging task.</p> Web-Based Bussiness <p>In web-based businesses, the usual flow involves a <code>request from a browser hitting the web server, then an application server, and finally, the database server</code>. This works well for a small user group, but as <code>users increase, bottlenecks emerge at each layer</code>\u2014first at the web server, then the application server, and finally, the database server. <code>Scaling out web servers is a common response, but it often shifts the bottleneck to the application server, which is more complex and costly to scale</code>. Even if the database is scaled (and even more costly to scale), the result is a <code>triangle-shaped topology</code>, with web servers being the easiest to scale and the database the hardest. </p> <p>Scalability limits within a traditional web-based topology from Fundamentals of Software Architecture.</p>"},{"location":"arch_styles/space_based_arch/#general-topology","title":"General Topology","text":"<p>Space-based architecture is rooted in the concept of <code>tuple space</code>, utilizing multiple parallel processors communicating through shared memory. <code>It achieves high scalability, elasticity, and performance by eliminating the central database as a synchronous constraint</code>. Instead, it relies on replicated in-memory data grids.</p> Tuple Space <p>A tuple space is an implementation of the associative memory paradigm for parallel/distributed computing. It provides a repository of tuples that can be accessed concurrently. As an illustrative example, consider that there are a group of processors that produce pieces of data and a group of processors that use the data. Producers post their data as tuples in the space, and the consumers then retrieve data from the space that match a certain pattern. This is also known as the blackboard metaphor. Tuple space may be thought as a form of distributed shared memory. Wikipedia link</p> <p><code>Application data is stored in-memory and replicated across all active processing units</code>. <code>When a unit updates data, it asynchronously sends it to the database via messaging with persistent queues</code>. Processing units dynamically start and shut down based on <code>user load</code>, addressing <code>variable scalability</code>. <code>With no central database bottleneck, near-infinite scalability is achieved</code>.</p> <p>Key components include processing units with application code, virtualized middleware for unit management, data pumps for asynchronous data updates to the database, data writers for database updates, and data readers delivering database data to processing units on startup.</p> <p>Example</p> <p></p> <p>Space-based architecture basic topology from Fundamentals of Software Architecture.</p>"},{"location":"arch_styles/space_based_arch/#processing-unit","title":"Processing Unit","text":"<p>The processing unit (as shown in the example image), <code>encompasses the application logic, both web-based components and backend business logic</code>. Its content varies depending on the application type. Smaller web-based apps might reside in a single processing unit, while larger ones may distribute functionality across multiple units based on application areas. The processing unit may also host small, single-purpose services (akin to microservices). <code>Alongside the application logic, it integrates an in-memory data grid and replication engine</code>, often implemented using products like Hazelcast, Apache Ignite, or Oracle Coherence.</p>"},{"location":"arch_styles/space_based_arch/#virtualized-middleware","title":"Virtualized Middleware","text":"<p>The virtualized middleware <code>manages architecture infrastructure, overseeing data synchronization and request handling</code>. It comprises components like a <code>messaging grid</code>, <code>data grid</code>, <code>processing grid</code>, and <code>deployment manager</code>.</p> <p>Messaging Grid</p> <p>The messaging grid <code>oversees input requests and session state</code>. Upon receiving a request, <code>it identifies available processing units and directs the request to one of them</code>. The complexity can range depending on the algorithm used from simple <code>round-robin</code> to <code>next-available</code>, <code>managed by a web server with load-balancing capabilities</code> (e.g., HA Proxy, Nginx).</p> <p>Data Grid</p> <p>The data grid stands out as a <code>pivotal component</code> in this architecture style. In modern implementations, <code>it resides within processing units as a replicated cache</code>. However, when setups <code>requiring an external controller or using a distributed cache, this functionality extends to both processing units and the virtualized middleware's data grid component</code>. As the messaging grid can route requests to any available processing unit, <code>maintaining identical data in each unit's in-memory grid is crucial</code>. Despite the synchronous data replication illustration below, actual synchronization is asynchronous and rapid, typically finishing in under 100 milliseconds.</p> <p></p> <p>Data grid from Fundamentals of Software Architecture.</p> <p><code>Data synchronization occurs among processing units that share the same named data grid</code>. For instance, consider an internal replicated data grid in processing units containing customer profile information, using Hazelcast. <code>Changes made to the CustomerProfile named cache in any processing unit replicate to all others with the same named cache</code>. <code>Each processing unit can hold multiple replicated caches as needed or request data from another unit (choreography) or leverage the processing grid for orchestration</code>.</p> <p>Data replication within processing units enables service instances to <code>start and stop without requiring data retrieval from the database, as long as one instance holds the named replicated cache</code>. When a processing unit instance starts, it connects to the cache provider (like Hazelcast), requests the named cache, and loads it from another instance.</p> <p><code>Each processing unit is aware of all others (including themselves) through a member list</code>, containing the IP addresses and ports of units <code>using the same named cache</code>. Suppose instance 1 receives a request to update customer profile information; <code>when it updates the cache, the data grid (e.g., Hazelcast) asynchronously updates other replicated caches, ensuring consistent synchronization</code>. <code>If processing unit instances go down, all others are automatically updated to reflect the lost member</code>.</p> <p>Processing Grid</p> <p>The processing grid, an <code>optional element in virtualized middleware</code>, oversees <code>coordinated request processing when multiple processing units are involved in a single business request</code>. If a request necessitates coordination between different processing unit types (e.g., an order processing unit and a payment processing unit), <code>the processing grid mediates and orchestrates the request between these units</code>.</p> <p>Deployment Manager</p> <p>The deployment manager component oversees the <code>dynamic startup and shutdown of processing unit instances based on load conditions</code>. Continually monitoring response times and user loads, it starts up new processing units with increased load and shuts down units during decreased load. <code>This critical component ensures variable scalability (elasticity) within an application</code>.</p>"},{"location":"arch_styles/space_based_arch/#data-pumps","title":"Data Pumps","text":"<p>A data pump is a <code>vital component</code> in space-based architecture, <code>facilitating the transfer of data to another processor for database updates</code>. Within this architecture, <code>processing units don't directly interact with databases</code>, making data pumps crucial. Asynchronous by nature, <code>data pumps ensure eventual consistency between the in-memory cache and the database</code>. When a processing unit updates its cache, it takes ownership of the update and uses the data pump to transmit the update to the database eventually.</p> <p>Implemented through messaging, data pumps offer <code>guaranteed delivery and preservation of message order through FIFO queueing</code>. This decoupling between the processing unit and the data writer <code>ensures uninterrupted processing</code>, even if the data writer is temporarily unavailable.</p> <p>Typically, <code>there are multiple data pumps, each dedicated to a specific domain or subdomain</code> (e.g., customer or inventory). They can be associated with specific caches (e.g., CustomerProfile, CustomerWishlist) or broader processing unit domains (e.g., Customer) with more extensive and general caches.</p> <p><code>Data pumps adhere to contracts</code>, defining actions (add, delete, update) associated with contract data. These contracts may take the form of <code>JSON</code> or <code>XML</code> schemas, objects, or value-driven messages. <code>For updates, the data pump message usually contains only the new data values</code>, such as the updated phone number and customer ID, along with an action to perform the update.</p> Example <p></p> <p>Data pump used to send data to a database from Fundamentals of Software Architecture.</p>"},{"location":"arch_styles/space_based_arch/#data-writers","title":"Data Writers","text":"<p>The data writer component plays a <code>crucial role</code> by <code>receiving messages from a data pump and utilizing the information within these messages to update the database</code>. Data writers can take the <code>form of services, applications, or data hubs</code> like Ab Initio. The scope of data writers varies based on the extent of the associated data pumps and processing units.</p> <p>A domain-based data writer <code>encapsulates the required database logic to manage updates within a specific domain</code>, such as customer information, irrespective of the number of data pumps it handles.</p> Example <p></p> <p>Domain-based data writer from Fundamentals of Software Architecture.  Dedicated data writers for each data pump from Fundamentals of Software Architecture.</p>"},{"location":"arch_styles/space_based_arch/#data-readers","title":"Data Readers","text":"<p>Data readers take on the responsibility for <code>reading data from the database and transmitting it to processing units through a reverse data pump</code>. Their <code>activation</code> is limited to specific scenarios:</p> <ol> <li>Crash of all processing unit instances of the same named cache.</li> <li>Redeployment of all processing units within the same named cache.</li> <li>Retrieving archive data not contained in the replicated cache.</li> </ol> <p>When <code>all instances go down</code>, indicating a system-wide crash or redeployment, <code>data must be read from the database, a practice typically avoided</code> in space-based architecture.</p> <p>When instances of a class of processing unit start coming up, <code>they attempt to gain a lock on the cache</code>, the first successful instance becomes the <code>temporary cache owner, initiating a message to a queue requesting data</code>, while the others go into a wait state until the lock is released. The data reader, upon receiving the read request, <code>executes the necessary database query logic to retrieve the required data</code>. As the data reader queries data, <code>it sends the results to a different queue known as a reverse data pump</code>. <code>The temporary cache owner processing unit loads the cache with the received data</code>. After loading all the data, the <code>temporary owner releases the lock, synchronizing all other instances</code>, allowing processing to commence.</p> <p>Similar to data writers, <code>data readers can be domain-based or dedicated to a specific class of processing unit</code>. Their implementation can take the form of services, applications, or data hubs.</p> <p><code>Together, data writers and data readers form a data abstraction layer</code>, ensuring processing units are decoupled from the underlying database table structures. In space-based architecture, a data abstraction layer allows incremental changes to the database without directly impacting the processing units.</p> Example <p></p> <p>Data reader with reverse data pump from Fundamentals of Software Architecture.</p>"},{"location":"arch_styles/space_based_arch/#data-collisions","title":"Data Collisions","text":"<p>Data collisions in space-based architecture with replicated caching can <code>arise when updates occur concurrently in service instances containing the same named cache</code>,due to replication latency. <code>Data updates made locally in one cache instance may be overridden by simultaneous updates from another cache instance during replication</code>.</p> <p>Example</p> <p>To illustrate this issue, consider two service instances (<code>Service A</code> and <code>Service B</code>) with a <code>replicated cache of product inventory</code>:</p> <ol> <li>Initial inventory count for <code>product Z is 500 units</code>.</li> <li><code>Service A updates</code> the inventory cache for product Z to 490 units (<code>10 sold</code>).</li> <li><code>Simultaneously</code>, during replication, <code>Service B updates</code> the inventory cache for product Z to 495 units (<code>5 sold</code>).</li> <li><code>Due to replication, the Service B cache is updated to 490 units, reflecting the Service A update</code>.</li> <li>Similarly, the <code>Service A cache is updated to 495 units, reflecting the Service B update</code>.</li> <li><code>Both caches in Service A and B are now incorrect and out of sync</code> (inventory should be 485 units).</li> </ol>"},{"location":"arch_styles/space_based_arch/#calculating-probability-to-data-collisions","title":"Calculating Probability to Data Collisions","text":"<p><code>Calculating the probability of data collisions involves considering factors</code>. The formula used to estimate the likelihood of potential data collisions incorporates these factors:</p> <p>Formula</p> <p><code>Collision Rate = N*(UR\u00b2/S)*RL</code></p> <p>Where:</p> <ol> <li>N    = number of service instances using the same named cache.</li> <li>UR   = update rate in milliseconds (squared).</li> <li>S    = cache size (in terms of number of rows)</li> <li>RL   = replication latency</li> </ol> <p>Base Example</p> <p><code>Collision Rate = N*(UR\u00b2/S)*RL</code></p> <ol> <li>N    = 5</li> <li>UR   = 20 updates/second</li> <li>S    = 50.000 rows</li> <li>RL   = 100 milliseconds = 0.1 seconds</li> </ol> <p>Collision Rate = 5 * (20\u00b2/50.000) * 0.1</p> <p>Collision Rate = 5 * (400/50.000) * 0.1</p> <p>Collision Rate = 5 * 0.008 * 0.1</p> <p><code>Collision Rate = 0.004 per second</code></p> <p>Updates per minute = 20 * 60 = 1200</p> <p><code>Updates per hour = 1200 * 60 = 72000</code></p> <p>Collision Rate per hour = 0.004 * 3600</p> <p><code>Collision Rate per hour = 14.4</code></p> <p>Percentage = 14.4 / 72000 * 100</p> <p><code>Percentage = 0.02%</code></p> <p>The formula provided is a valuable tool for assessing the likelihood of data collisions and <code>determining the feasibility of using replicated caching in a space-based architecture</code>. <code>Replication latency</code>, influenced by network type and physical distance between processing units, <code>plays a crucial role in data consistency</code>. While actual replication latency values are often not readily available and need to be measured in a production environment, <code>a planning value of 100 milliseconds is commonly used when precise figures are unavailable</code>.</p> Reducing Replication Latency <p>Changing the replication latency from 100 milliseconds to 1 millisecond yields the same number of updates (72,000 per hour) but <code>produces only the probability of 0.1 collisions per hour</code>.</p> <p><code>Collision Rate = N*(UR\u00b2/S)*RL</code></p> <ol> <li>N    = 5</li> <li>UR   = 20 updates/second</li> <li>S    = 50.000 rows</li> <li>RL   = 1 milliseconds = 0.001 second</li> </ol> <p>Collision Rate = 5 * (20\u00b2/50.000) * 0.001</p> <p>Collision Rate = 5 * (400/50.000) * 0.001</p> <p>Collision Rate = 5 * 0.008 * 0.001</p> <p><code>Collision Rate = 0.00004 per second</code></p> <p>Updates per minute = 20 * 60 = 1200</p> <p><code>Updates per hour = 1200 * 60 = 72000</code></p> <p>Collision Rate per hour = 0.00004 * 3600</p> <p><code>Collision Rate per hour = 0.144</code></p> <p>Percentage = 0.144 / 72000 * 100</p> <p><code>Percentage = 0.0002%</code></p> <p><code>The number of processing units sharing the same named cache (represented by the number of instances) has a direct proportional relationship with the potential number of data collisions</code>.</p> Decreasing Processing Units <p>Reducing the number of processing units from 5 instances to 2 instances yields a <code>data collision rate of only 6 per hour out of 72,000 updates per hour</code>:</p> <p><code>Collision Rate = N*(UR\u00b2/S)*RL</code></p> <ol> <li>N    = 2</li> <li>UR   = 20 updates/second</li> <li>S    = 50.000 rows</li> <li>RL   = 100 milliseconds = 0.1 seconds</li> </ol> <p>Collision Rate = 2 * (20\u00b2/50.000) * 0.1</p> <p>Collision Rate = 2 * (400/50.000) * 0.1</p> <p>Collision Rate = 2 * 0.008 * 0.1</p> <p><code>Collision Rate = 0.0016 per second</code></p> <p>Updates per minute = 20 * 60 = 1200</p> <p><code>Updates per hour = 1200 * 60 = 72000</code></p> <p>Collision Rate per hour = 0.0016 * 3600</p> <p><code>Collision Rate per hour = 5.76</code></p> <p>Percentage = 5.76 / 72000 * 100</p> <p><code>Percentage = 0.008%</code></p> <p><code>Cache size is inversely proportional to collision rates, meaning that as the cache size decreases, collision rates increase</code>.</p> Smaller Cache Size <p>Reducing the cache size from 50,000 to 10,000 rows, while keeping other factors constant, <code>increases the collision rate to 72 per hour, emphasizing the impact of cache size on collision probability</code>.</p> <p>Collision Rate = N(UR\u00b2/S)RL`</p> <ol> <li>N    = 5</li> <li>UR   = 20 updates/second</li> <li>S    = 10.000 rows</li> <li>RL   = 100 milliseconds = 0.1 seconds</li> </ol> <p>Collision Rate = 5 * (20\u00b2/10.000) * 0.1</p> <p>Collision Rate = 5 * (400/10.000) * 0.1</p> <p>Collision Rate = 5 * 0.04 * 0.1</p> <p><code>Collision Rate = 0.02 per second</code></p> <p>Updates per minute = 20 * 60 = 1200</p> <p><code>Updates per hour = 1200 * 60 = 72000</code></p> <p>Collision Rate per hour = 0.02 * 3600</p> <p><code>Collision Rate per hour = 72</code></p> <p>Percentage = 72 / 72000 * 100</p> <p><code>Percentage = 0.1%</code></p> <p>In a typical scenario, <code>systems don't maintain consistent update rates over extended periods</code>. Therefore, when using this calculation, <code>understanding the maximum update rate during peak usage and calculating minimum, normal, and peak collision rates can provide a more nuanced perspective</code>.</p>"},{"location":"arch_styles/space_based_arch/#cloud-vs-on-premises-implementations","title":"Cloud vs On-Premises Implementations","text":"<p><code>Space-based architecture provides versatile deployment options, allowing the entire system</code>, including processing units, virtualized middleware, data pumps, data readers and writers, and the database, <code>to be implemented either in on-premises environments or within cloud-based environments</code>. Additionally, this architecture style offers a unique capability to <code>deploy applications using processing units and virtualized middleware in managed cloud environments while retaining physical databases and associated data on-premises</code>.</p> <p>A key strength of this architecture lies in the possibility of deploying applications through <code>processing units and virtualized middleware in managed cloud-based environments while maintaining physical databases and associated data on-premises</code>. This configuration <code>facilitates highly efficient cloud-based data synchronization</code>, leveraging asynchronous data pumps and the eventual consistency model inherent in this architecture. <code>The setup allows for transactional processing in dynamic and elastic cloud-based environments while upholding the management of physical data, reporting, and data analytics securely within the local and on-premises environments</code>.</p> Example <p></p> <p>Hybrid cloud-based and on-prem topology from Fundamentals of Software Architecture.</p>"},{"location":"arch_styles/space_based_arch/#replicated-vs-distributed-caching","title":"Replicated vs Distributed Caching","text":"<p><code>Space-based architecture heavily relies on caching to facilitate the transactional processing of an application</code>. While the <code>predominant caching model is replicated caching</code>, space-based architecture can also leverage <code>distributed caching</code>.</p> <p><code>In replicated caching, each processing unit possesses its in-memory data grid synchronized among all units using the same named cache</code>. This method is not only <code>exceptionally fast but also offers robust fault tolerance</code>, as there's no central server acting as a single point of failure.</p> About Replicate Cache and Single Point of Failure <p>Some exceptions may exist based on the caching product's implementation, but the trend is moving away from relying on external controllers for replication.</p> <p>Replicated caching is the standard for space-based architecture, but certain scenarios, <code>such as high data volumes or update rates, may necessitate the use of distributed caching</code>. <code>Internal memory caches exceeding 100 MB can pose challenges for elasticity and scalability, and in situations with high update rates, distributed caching becomes a viable alternative</code>. Furthermore, as shown in Data Collisions, in situations where the <code>update rate of cache data becomes too high, and the data grid struggles to maintain consistency across all processing unit instances</code>, distributed caching can be a viable solution.</p> <p><code>Distributed caching involves an external server or service dedicated to maintaining a centralized cache</code>. Processing units access data from this central cache server through a <code>proprietary protocol</code>. <code>While distributed caching ensures high data consistency due to the centralized nature of the data, it comes with performance trade-offs, as accessing cache data remotely adds latency to the system</code>. <code>Fault tolerance can be a concern, and mirroring the distributed cache is one approach to mitigate it, though it may introduce consistency issues</code>.</p> <p>Example</p> <p></p> <p>Distributed caching between processing units from Fundamentals of Software Architecture.</p> <p>Choosing between replicated and distributed caching depends on factors such as <code>data consistency needs, performance considerations, and fault tolerance requirements</code>. <code>Distributed caching excels in maintaining highly consistent data, while replicated caching offers better performance and fault tolerance</code>. Often, <code>both models can be applicable within a single application context</code>, allowing each to be leveraged based on its specific strengths. For instance, a <code>distributed caching model may be suitable for maintaining consistently critical data</code> like inventory counts, while a <code>replicated cache may be chosen for performance and fault tolerance in managing less dynamic data</code> like customer profiles.</p> Decision criteria Replicated cache Distributed cache Optimization Performance Consistency Cache size Small(&lt;100MB) Large(&gt;500MB) Type of data Relatively static Highly dynamic Update frequency Relatively low High update rate Fault tolerance High Low"},{"location":"arch_styles/space_based_arch/#implementation-examples","title":"Implementation Examples","text":"<p><code>Space-based architecture proves effective for applications experiencing high spikes in user or request volume</code>, especially those surpassing 10,000 concurrent users.</p>"},{"location":"arch_styles/space_based_arch/#concert-ticketing-system","title":"Concert Ticketing System","text":"<p>Concert ticketing systems face unique challenges, particularly during popular concert announcements <code>when user volumes skyrocket from hundreds to potentially tens of thousands</code>. <code>Constantly accessing a central database synchronously in such systems would likely not work</code>. The sheer volume of tens of thousands of concurrent requests, coupled with the rapid update frequency, makes it exceedingly difficult for a standard database to handle through conventional synchronous transactions at this scale.The architecture's <code>high elasticity is crucial</code> for handling these sudden spikes.</p> <p><code>Space-based architecture allows instant recognition of increased user demand, prompting the deployment manager to initiate numerous processing units to efficiently manage the surge</code>. Configuring the deployment manager to start these instances right before ticket sales ensures optimal performance.</p>"},{"location":"arch_styles/space_based_arch/#online-auction-system","title":"Online Auction System","text":"<p>Online auction systems share similarities with concert ticketing in terms of <code>high performance and elasticity demands</code>, coupled with unpredictable user and request spikes. <code>Space-based architecture excels in this context by allowing the dynamic creation and destruction of processing units based on changing load conditions</code>. Dedicated processing units for each auction ensure data consistency, and the asynchronous nature of data pumps facilitates swift transmission of bidding data to various processing units, enhancing overall bidding process performance.</p>"},{"location":"basic/architectural_thinking/","title":"Architectural Thinking","text":"<p>A software architecture goes beyond mere \"thinking about the architecture.\" It encompasses various crucial aspects that architects need to consider, including:</p> <ul> <li> <p>Architecture vs. Design: It is important to distinguish between architecture and design and effectively collaborate with development teams to align their efforts.</p> </li> <li> <p>Technical Breadth: It involves having a broad range of technical knowledge while maintaining a certain level of depth. This allows architects to see solutions and possibilities that others do not see.</p> </li> <li> <p>Analyzing Trade-Offs: Architects should understand, analyze, and reconcile trade-offs between different solutions and technologies.</p> </li> <li> <p>Understanding Business Drivers: Understand the importance of business drivers and how they translate to architectural concerns.</p> </li> </ul>"},{"location":"basic/architectural_thinking/#architecture-vs-design","title":"Architecture vs. Design","text":"<p>The distinction between architecture and design can be confusing at times. It raises questions about the roles and responsibilities of architects compared to developers. However, an architect possesses the knowledge and understanding to differentiate between architecture and design. They recognize how these two aspects intricately intertwine to create comprehensive solutions for both business and technical challenges.</p>"},{"location":"basic/architectural_thinking/#traditional-and-wrong-thinking","title":"Traditional and Wrong Thinking","text":"<p>Traditional view of architecture versus design from Fundamentals of Software Architecture.</p> <p>The traditional viewpoint described in the image below is rarely effective. It often leads to a disconnect between the architect and the development team. Architectural decisions made by the architect may not reach the development team, and conversely, decisions made by the development team may not be communicated back to the architect. This lack of communication and coordination can result in changes to the architecture that were never intended or considered by the architect.</p>"},{"location":"basic/architectural_thinking/#the-right-thinking","title":"The Right Thinking","text":"<p>Making architecture work through collaboration from Fundamentals of Software Architecture.</p> <p>For effective architecture, there should be no barriers between architects and developers. It is crucial to establish a strong, bi-directional relationship between them. This allows architects to provide mentoring and coaching to the development team. Architecture and design are intertwined aspects within the software project lifecycle and must always collaborate closely.</p>"},{"location":"basic/architectural_thinking/#technical-breadth","title":"Technical Breadth","text":"<p>A significant aspect of an architect's value lies in their comprehensive understanding of technology and its application to solving specific problems. Rather than having expertise in only one solution, it is more advantageous for an architect to be aware of multiple solutions available for a given problem.</p> <p>In the realm of architecture, breadth of knowledge outweighs depth. Architects are tasked with making decisions that align capabilities with technical constraints. Therefore, having a broad understanding of a wide range of solutions holds immense value.</p>"},{"location":"basic/architectural_thinking/#analyzing-trade-offs","title":"Analyzing Trade-Offs","text":"<p>Architecture is the stuff you can\u2019t Google. There are no right or wrong answers in architecture\u2014only trade-offs. Programmers know the benefits of everything and the trade-offs of nothing. Architects need to understand both.</p> <p>Adopting an architectural mindset involves recognizing trade-offs in every solution, whether they are technical or non-technical, and meticulously analyzing them to determine the optimal choice.</p> <p>In architecture, trade-offs permeate every aspect, which is why the universal response to architecture questions is often \"it depends.\" The optimal solution hinges on various factors such as the deployment environment, business drivers, company culture, budgets, timeframes, developer skill sets, and numerous other considerations.</p> <p>As an architect, the ability to navigate these trade-offs is crucial. It entails carefully evaluating the benefits and drawbacks of different options and striking a balance that aligns with the specific project requirements and constraints. Making informed decisions based on a thorough analysis of trade-offs ensures the chosen solution is well-suited to the unique context of the architecture project.</p>"},{"location":"basic/architectural_thinking/#understanding-business-drivers","title":"Understanding Business Drivers","text":"<p>Thinking like an architect entails comprehending the essential business drivers necessary for the system's success and effectively translating those requirements into architectural characteristics like scalability, performance, and availability. This task presents a significant challenge, as it demands architects to possess a certain level of business domain knowledge and foster collaborative relationships with key business stakeholders. By understanding the underlying business needs and aligning them with the architectural decisions, architects can design solutions that meet both technical and business objectives, ensuring the overall success of the system.</p>"},{"location":"basic/architectural_thinking/#references","title":"References","text":"<ul> <li>Fundamentals of Software Architecture</li> </ul>"},{"location":"basic/expectations_of_architect/","title":"Expectations of an Architect","text":"<p>Defining the role of a software architect can be challenging, as it encompasses various aspects. However, it is essential to outline the expectations and responsibilities associated with the architect's role.</p> <ul> <li>Make architecture decisions</li> <li>Continually analyze the architecture</li> <li>Keep current with latest trends</li> <li>Ensure compliance with decisions</li> <li>Diverse exposure and experience</li> <li>Have business domain knowledge</li> <li>Possess interpersonal skills</li> <li>Understand and navigate politics</li> </ul>"},{"location":"basic/expectations_of_architect/#make-architecture-decisions","title":"Make architecture decisions","text":"<p>An architect is expected to define the architecture decisions and design principles used to guide technology decisions within the team, the department, or across the enterprise.</p> <p>When it comes to making architecture decisions, guidance is crucial. Instead of strictly specifying technology choices, the role of an architect  should guide rather than specify technology choices.</p> <p>For instance, rather than explicitly stating that React.js should be used for the frontend, which is a technical decision, the architect should guide development teams towards choosing a reactive-based framework for the frontend, offering options like Angular, React.js, Vue.js, and others. It is important to assess whether the architecture decision is guiding teams to make their own technical choices or if it imposes a specific technology upon them, which may hinder their decision-making process.</p> <p>While the role of an architect primarily focuses on guiding rather than specifying technology choices, there are situations where specific technology decisions become necessary to preserve a particular architectural characteristics like scalability, performance, or availability. Even though these decisions involve choosing a particular technology, they still fall within the realm of architectural decisions.</p> <p>However, it's important to acknowledge that finding the right decision in such cases can be challenging. The topic of making architecture decisions will be further explored and discussed in subsequent sections.</p>"},{"location":"basic/expectations_of_architect/#continually-analyze-the-architecture","title":"Continually analyze the architecture","text":"<p>An architect is expected to continually analyze the architecture and current technology environment and then recommend solutions for improvement.</p> <p>This responsibility refers to architecture vitality, analyzing how well the architecture can sustain itself over time. It is not a common concern, as many architectures encounter structural decay when developers introduce code or design changes that affect the required architectural characteristics.</p> <p>Additionally, testing and release environments often tend to be overlooked in this context. If the testing and release processes consume excessive time, it becomes challenging to achieve overall agility in the architecture.</p>"},{"location":"basic/expectations_of_architect/#keep-current-with-latest-trends","title":"Keep current with latest trends","text":"<p>An architect is expected to keep current with the latest technology and industry trends.</p> <p>Keeping up with the latest trends is crucial for staying relevant in the field of architecture. The decisions made by an architect often have long-lasting effects and can be challenging to modify later on. By actively staying informed about and embracing key trends, architects can better prepare for the future and make well-informed decisions that align with industry advancements. This proactive approach ensures that architectural decisions are forward-thinking and capable of meeting evolving needs and challenges.</p>"},{"location":"basic/expectations_of_architect/#ensure-compliance-with-decisions","title":"Ensure compliance with decisions","text":"<p>An architect is expected to ensure compliance with architecture decisions and design principles.</p> <p>One of the key responsibilities of an architect is to ensure that development teams are following the architecture decisions and design principles. By enforcing compliance, the architect helps prevent violations that could compromise the desired architectural characteristics and impede the expected functionality of the application or system.</p> <p>For instance, consider a scenario where there is a restriction on database access, allowing only the business and services layers (excluding the presentation layer) to communicate with the database. This architectural decision necessitates passing through all layers, even for a simple query originating from the presentation layer. However, this decision serves a specific purpose: to control changes. By enforcing this approach, database modifications can be implemented without affecting the presentation layer, thus ensuring a greater degree of flexibility and mitigating potential disruptions.</p>"},{"location":"basic/expectations_of_architect/#diverse-exposure-and-experience","title":"Diverse exposure and experience","text":"<p>An architect is expected to have exposure to multiple and diverse technologies, frameworks, platforms, and environments.</p> <p>As an architect, it is not necessary to be an expert in every framework, platform, or programming language. However, it is crucial to have a diverse exposure and familiarity with a variety of technologies. This includes knowing how to interface with multiple systems and services based on different technologies.</p> <p>A skilled software architect actively seeks opportunities to gain experience in various languages, platforms, and technologies. Rather than focusing solely on technical depth, it is important to prioritize technical breadth. For example, instead of being an expert in just one caching product, it is more valuable for an architect to be familiar with the features, advantages, and disadvantages of multiple caching products. This broader understanding allows for informed decision-making when choosing the most suitable caching solution for a given scenario.</p> <p>By continuously expanding their technical breadth, an architect can effectively navigate diverse technology landscapes, make informed decisions, and provide valuable guidance in selecting the right tools and technologies for a project. This breadth of exposure and experience enhances their ability to design robust and scalable solutions that align with business requirements.</p>"},{"location":"basic/expectations_of_architect/#have-business-domain-knowledge","title":"Have business domain knowledge","text":"<p>An architect is expected to have a certain level of business domain expertise.</p> <p>Having a strong understanding of the business domain is a fundamental expectation for an architect. Without this knowledge, it becomes challenging to comprehend the business problem, goals, and requirements, making it difficult to devise an effective architecture. Additionally, lacking business domain knowledge diminishes the architect's credibility when communicating with stakeholders and business users.</p>"},{"location":"basic/expectations_of_architect/#possess-interpersonal-skills","title":"Possess interpersonal skills","text":"<p>An architect is expected to possess exceptional interpersonal skills, including teamwork, facilitation, and leadership.</p> <p>Being an effective software architect involves more than just providing technical guidance. It requires possessing strong interpersonal skills and the ability to lead development teams through the implementation of the architecture. In fact, leadership skills are considered equally important, if not more so, than technical expertise for a successful architect.</p>"},{"location":"basic/expectations_of_architect/#understand-and-navigate-politics","title":"Understand and navigate politics","text":"<p>An architect is expected to understand the political climate of the enterprise and be able to navigate the politics.</p> <p>In the realm of software architecture, it is essential for architects to possess the ability to understand and navigate the intricacies of organizational politics. While developers often have the freedom to make alterations like refactoring code using the strategy pattern without seeking approval, architects face different challenges.</p> <p>Consider a scenario where an architect is responsible for a large customer relationship management (CRM) system and encounters issues with controlling database access from other systems. To address this, the architect decides to implement application silos, ensuring that each application's database is accessible only to the corresponding application. This decision empowers the architect to have better control over customer data, security, and change control.</p> <p>However, unlike the previous developer scenario, architectural decisions of this magnitude are likely to be met with resistance from various stakeholders within the company. For instance, if other applications can no longer access the database directly, they would need to request data from the CRM system through remote access calls using protocols like REST or SOAP. This shift in approach triggers challenges from different quarters. Product owners, project managers, and business stakeholders may express concerns about increased costs or additional effort required. Developers may also challenge the decision, presenting alternative approaches they believe to be superior.</p> <p>In such situations, architects must skillfully navigate the company's politics and employ effective negotiation techniques to gain approval for their decisions.</p>"},{"location":"basic/expectations_of_architect/#references","title":"References","text":"<ul> <li>Fundamentals of Software Architecture</li> </ul>"},{"location":"basic/whats_software_arc/","title":"What is Software Architecture?","text":"<p>Software Architecture is a dynamic and complex field that continues to evolve rapidly. Recent years have witnessed advancements such as CI/CD, microservices, containerization, and cloud-based resources. These innovations bring new capabilities and trade-offs to consider.</p> <p>In software development, understanding trade-off analysis is crucial for making informed decisions. This repository emphasizes analyzing trade-offs rather than passing judgments on technologies.</p> <p>It is crucial to recognize that architectures are shaped by their context. Architectural decisions are often influenced by the realities of the environment they operate in. For instance, attempting to implement a microservices architecture in 2002 would have been impractical.</p>"},{"location":"basic/whats_software_arc/#defining-software-architecture","title":"Defining Software Architecture","text":"<p>Defining Software Architecture is challenging due to various interpretations. It may be seen as the blueprint or roadmap for a system. However, what aspects does an architect analyze when examining an architecture?</p> <p>One definition in Fundamentals of Software Architecture is illustrated on the image bellow. In this definition, software architecture consists of the structure of the system, combined with architecture characteristics the system must support, architecture decisions, and design principles.</p> <p></p> <p>Architecture consists of the structure combined with architecture characteristics (\u201c-ilities\u201d), architecture decisions, and design principles</p>"},{"location":"basic/whats_software_arc/#structure","title":"Structure","text":"<p>Structure refers to the type of architecture styles used in the system</p> <p>The system structure refers to the architecture style(s) implemented in the system, like microservices, layered, or microkernel. However, it's important to note that the system structure alone does not fully describe a system architecture.</p>"},{"location":"basic/whats_software_arc/#architecture-characteristics","title":"Architecture characteristics","text":"<p>Architecture characteristics refers to the \u201c-ilities\u201d that the system must support</p> <p>Architecture characteristics define the success criteria for a system, independent of its functionality. They are essential for the system to function correctly and do not necessarily rely on knowing the specifics of its functionality.</p>"},{"location":"basic/whats_software_arc/#architecture-decisions","title":"Architecture decisions","text":"<p>Architecture decisions are rules for constructing systems</p> <p>Architecture decisions establish the guidelines for system construction. They impose constraints and provide direction to development teams, outlining what is permissible and what is not within the system.</p>"},{"location":"basic/whats_software_arc/#design-principles","title":"Design principles","text":"<p>Design principles are guidelines for constructing systems</p> <p>The design principles is a guideline rather than a hard-and-fast rule like architecture decisions. As an example, the design principle depicted in the image above guides development team to utilize asynchronous messaging for improved performance in a microservice architecture. Architecture decisions cannot account for every communication scenario between services. Hence, design principles offer guidance, such as employing async messaging, enabling developers to choose suitable communication protocols like REST or gRPC.</p>"},{"location":"basic/whats_software_arc/#references","title":"References","text":"<ul> <li>Fundamentals of Software Architecture</li> </ul>"},{"location":"components/","title":"Components","text":"<p>Modules are groups of related code, but architects often focus on <code>components, which are the physical versions of modules</code>. These components are packaged differently depending on the programming language, such as jar files in Java or DLLs in .NET.</p>"},{"location":"components/#component-scope","title":"Component Scope","text":"<p>Components provide a language-specific way to group artifacts together, often by nesting them to create layers. It's helpful to divide the concept of components as shown in the image below.</p> <p></p> <p>Different varieties of components from Fundamentals of Software Architecture.</p> Wrapper of Related Code <p>The simplest form of a component is one that <code>wraps code at a higher level of modularity than classes or functions</code>. This is often <code>referred to as a library</code>. Libraries typically run in the same memory address as the calling code and communicate via language function call mechanisms. Libraries are usually compile-time dependencies.</p> Layer or Subsystem &amp; Event Processor <p>Components can also take the form of subsystems or layers within an architecture, serving as the deployable units of work for many event processors.</p> Distributed Service <p>Distributed services tend to <code>run in their own separate address spaces and communicate</code> using low-level networking protocols like TCP/IP or higher-level formats like REST or message queues. <code>They are stand-alone and deployable units in architectures</code> such as microservices.</p> <p><code>Components are the basic building blocks in architecture</code> and are a crucial consideration for architects. <code>One of the key decisions architects must make is how to divide the architecture into top-level components</code>. While architects are not obligated to use components, they often find them beneficial as they provide a higher level of modularity.</p>"},{"location":"components/#architect-role","title":"Architect Role","text":"<p><code>The architect typically plays a central role in defining, refining, managing, and overseeing components within an architecture</code>.  This work is done in collaboration with various stakeholders, including business analysts, subject matter experts, developers, QA engineers, operations teams, and enterprise architects, to create the initial software design.</p> <p>In most cases, components represent the lowest level of the software system that an architect directly interacts with. These components are composed of classes or functions, depending on the implementation platform. The detailed design of these classes or functions often falls under the responsibility of tech leads or developers. While <code>architects may involve themselves in class design, especially when applying design patterns, they should avoid micromanaging every decision throughout the system</code>. Allowing other roles to make significant decisions is essential for empowering the next generation of architects.</p> <p><code>One of the architect's initial tasks on a new project is to identify components</code>. However, before doing so, architects must have a clear understanding of how to partition the overall architecture effectively.</p>"},{"location":"components/#architecture-partitioning","title":"Architecture Partitioning","text":"<p>In software architecture, <code>there are always trade-offs to consider, including how architects design components within an architecture</code>. <code>Components serve as general containers, allowing architects to structure the system as they see fit</code>. There are several common styles available, each with its own set of trade-offs to consider.</p> <p>Let's consider two common architecture styles shown below.</p> <p></p> <p>Two types of top-level architecture partitioning: layered and modular from Fundamentals of Software Architecture.</p> Technical Partitioning as a version of Layer Monolith <p>In the layer monolith, <code>the architecture is divided into layers</code> each with specific responsibilities.</p> Domain Partitioning as a version of Modular Monolith <p>In the modular monolith, <code>organized around domains or business functionalities</code></p> <p>It's important to note that in each of these variations, <code>the top-level components (layers or components) often contain embedded sub-components</code>. The choice of <code>top-level partitioning is a critical decision for architects, as it defines the fundamental architecture style and the way code is organized</code>.</p>"},{"location":"components/#technical-partitioning","title":"Technical Partitioning","text":"<p>When organizing a codebase <code>through technical partitioning, code is grouped based on its technical aspects</code>.  For instance, code responsible for interacting with a database is placed in the persistence layer. This approach ensures that <code>code with similar technical concerns resides within a single layer of the architecture</code>.</p> Model-View-Controller (MVC) <p>One classic example of this approach is the <code>Model-View-Controller (MVC)</code> design pattern. <code>MVC separates code into distinct components</code>, including the model (data and logic), view (user interface), and controller (intermediary between model and view). <code>This separation simplifies code organization and enhances comprehensibility</code>.</p> <p>In technical partitioning, a key principle is to separate technical concerns. <code>This separation results in different levels of decoupling</code>. For instance, if we consider the <code>service layer</code>, it's primarily connected to the persistence layer below it and the business rules layer above it. <code>This means that any changes made to the persistence layer will likely only impact these adjacent layers</code>.</p> <p>This partitioning style is valuable because it <code>minimizes the potential for changes in one part of the system to create significant impacts on other components</code>. It helps reduce the cascading effects of modifications on dependent parts of the architecture.</p> <p>In layered architecture, <code>there's an interesting impact on how companies organize their project teams.</code> It often leads to a situation where backend developers work together in one department, database administrators (DBAs) in another, and the presentation team in yet another department.</p>"},{"location":"components/#domain-partitioning","title":"Domain Partitioning","text":"<p>Another way to structure architecture is through domain partitioning, which is <code>inspired by the Domain-Driven Design (DDD) approach</code>. In DDD, architects <code>identify separate and independent domains or workflows</code> within a complex software system. While each of these domains may have its own layers, such as a business rules layer and its own persistence library, <code>the main focus of domain partitioning is on these separate domains</code>. For instance, CatalogCheckout represents a specific domain within your system. And may have a diffent persistence library than others components.<code>This approach aligns well with how changes typically happen in projects</code>.</p> <p>In a <code>technically layered architecture, a common business workflow like CatalogCheckout is spread across multiple layers</code>, with code related to it present in each layer. However, in <code>domain partitioning, CatalogCheckout's code is concentrated within its own sub-component</code>, resulting in a more focused and organized structure.</p>"},{"location":"components/#developer-role","title":"Developer Role","text":"<p>Developers often work with components that have been collaboratively designed with architects, breaking them down into classes, functions, or subcomponents. The responsibility for designing classes and functions is usually shared among architects, tech leads, and developers, with a significant portion falling on the developer's shoulders.</p> <p><code>It's important to note that developers shouldn't consider the architect's design as final</code>. Software design is an iterative process, and the initial design should be seen as a starting point. During implementation, more details and refinements may emerge, leading to improvements in the design.</p>"},{"location":"components/#component-identification-flow","title":"Component Identification Flow","text":"<p>Identifying components is <code>best achieved through an iterative process that generates candidates and refines them based on feedback</code>. The following stages outline a typical component identification workflow. In certain specialized domains, additional steps may be introduced, such as security or auditing procedures, to adapt to specific requirements.</p> Identifying Initial Components <p>In the early stages of a software project, <code>architects face the task of determining the initial top-level components</code>. This choice is <code>influenced by the type of</code> top-level partitioning they select. Beyond this, architects have the creative freedom to define components as they see fit, and then align domain functionality with these components to <code>determine where specific behaviors should reside</code>.</p> <p>It's important to note that <code>achieving an optimal design with this initial set of components is quite challenging</code>. This is why architects must engage in an iterative process of component design refinement to enhance the overall system design.</p> Assign Requirements to Components <p>Once an architect has identified the initial components, the <code>next step is to see how the project's requirements or user stories fit with these components</code>. It might involve creating new components, consolidating existing ones, or even splitting components if they carry too much responsibility.</p> <p>Remember, <code>this doesn't have to be super precise right away. The main goal is to create a basic structure that can be adjusted and improved</code> as the project progresses, with input from architects, tech leads, and developers.</p> Analyze Roles and Responsibilities <p>The architect also <code>checks if the roles and responsibilities mentioned in the requirements match the component granularity</code>. This means making sure that the way people and tasks are organized aligns with how the components are structured. <code>Finding the right level of granularity for components can be challenging, which is why this iterative process is crucial</code>.</p> Analyze Architecture Characteristics <p><code>When assigning requirements to components, architects should consider the previously identified architecture characteristics</code>. For example, if one part of the system deals with many users simultaneously, and another part with only a few, their architectural needs will vary. While a simple approach might suggest one component for user interaction, analyzing the architecture characteristics may lead to splitting it into multiple components. <code>This helps tailor the design to the system's specific requirements</code>.</p> Restructure Components <p><code>Feedback plays a crucial role in software design</code>. Architects must continuously refine their component design in collaboration with developers. <code>Designing software often presents unexpected challenges, and it's impossible to anticipate every issue that may arise</code>. Therefore, an iterative approach to component design is essential.</p> <p>Firstly, it's challenging to foresee all the unique scenarios and edge cases that might require redesign. Secondly, <code>as the architecture and development progress, a more nuanced understanding of where specific functions and responsibilities should reside emerges</code>. This iterative process allows for a more robust and adaptable software design.</p>"},{"location":"components/#component-design","title":"Component Design","text":"<p>Creating a component design involves <code>many techniques, each with its own pros and cons</code>. <code>The architect's job is to analyze requirements and decide on the fundamental building blocks for the application</code>. These techniques vary depending on the team's development process and organizational preferences.</p> <p>Architects, often <code>working with others, establish an initial component design based on their understanding of the system and their chosen approach for breaking it down</code>, whether by technical or domain considerations. The aim is to create an <code>initial design that divides the problem into manageable chunks while considering various architecture aspects</code>.</p> Entity Trap <p>The entity trap is a common anti-pattern illustrated in the image below.</p> <p></p> <p>Building an architecture as an object-relational mapping from Fundamentals of Software Architecture.</p> <p>It occurs when an architect <code>creates components for each entity identified in the requirements, resembling an object-relational mapping (ORM) framework for a database</code>. This approach is not true architecture but rather a way to handle simple database CRUD operations. ORM frameworks are available for this purpose.</p> <p>The problem with the entity trap is that it <code>inaccurately maps database relationships to application workflows, which is rarely the case in practice</code>. This anti-pattern typically reflects a <code>lack of consideration for the actual application workflows</code>.</p>"},{"location":"components/#actoractions-approach","title":"Actor/Actions Approach","text":"<p>The actor/actions approach is a common method that architects use to align requirements with components. In this approach, inspired by the Rational Unified Process, <code>architects identify actors who interact with the application and define the actions these actors can perform</code>. This approach helps discover the typical users of the system and the actions they might take.</p> <p>The actor/actions approach remains popular and is <code>effective when requirements involve distinct roles and their associated actions</code>. <code>This method of component design is suitable for various types of systems, whether they are monolithic or distributed</code>.</p>"},{"location":"components/#event-storming-approach","title":"Event Storming Approach","text":"<p>The event storming approach to component discovery originates from domain-driven design (DDD) and is closely associated with microservices. In event storming, <code>the architect anticipates that the project will rely on messages and events for communication between components</code>. To implement this, <code>the team identifies the events that take place in the system based on requirements and identified roles</code>. Components are then built around these event and message handlers. <code>This approach is particularly effective in distributed architectures like microservices that heavily rely on events and messages, as it assists architects in defining the messages used in the system</code>.</p>"},{"location":"components/#workflow-approach","title":"Workflow Approach","text":"<p>An alternative to event storming, <code>which provides a more generic option for architects who are not utilizing domain-driven design (DDD) or messaging</code>. In the workflow approach, c<code>omponents are designed around workflows, similar to event storming, but without the specific requirement of constructing a message-based system</code>. <code>This approach involves identifying key roles, determining the types of workflows these roles are involved in, and then creating components based on these identified activities</code>.</p>"},{"location":"components/#references","title":"References","text":"<ul> <li>Fundamentals of Software Architecture</li> </ul>"},{"location":"modularity/","title":"Modularity","text":"<p>95% of the words [about software architecture] are spent extolling the benefits of \u201cmodularity\u201d and that little, if anything, is said about how to achieve it.</p> <p>Modularity is a <code>fundamental organizing principle</code> in software architecture. If an architect neglects how the components of a system interconnect, it can lead to numerous problems.</p> <p>Although the concept of modularity is widely recognized in software architecture, it can be elusive to precisely define. These modules serve as a <code>means of encapsulating functionality, promoting code organization, and enhancing maintainability</code>.</p> <p>Maintaining good modularity embodies an <code>implicit architectural characteristic</code>: most projects may not explicitly demand the architect to ensure it, but sustainable code bases necessitate order and consistency in modular distinction and communication. A well-organized system with clear boundaries between modules fosters code reusability, ease of maintenance, and scalability, contributing to the long-term success of the project.</p>"},{"location":"modularity/#definition","title":"Definition","text":"<p>Modularity refers to the <code>logical grouping of related code</code>, whether it's classes in an object-oriented language or functions in a structured or functional language. Developers commonly employ modules to organize and group related code together.</p> <p>For architects, understanding how developers package code is crucial, as it significantly impacts the architecture. <code>Tight coupling between packages can make it challenging to reuse one of them for related tasks</code>.</p>"},{"location":"modularity/measuring/","title":"Measuring Modularity","text":""},{"location":"modularity/measuring/#cohesion","title":"Cohesion","text":"<p>Cohesion is a <code>measure of the relationship between parts within a module</code>. In an ideal scenario, a cohesive module contains parts that <code>should remain together</code> since breaking them into smaller pieces would result in increased coupling between modules.</p> <p>Cohesion measures can be ranked from best to worst:</p> <ol> <li> <p>Functional Cohesion: <code>Every part of the module is related to the other</code>, and the module contains everything essential to function.</p> </li> <li> <p>Sequential Cohesion: Two modules interact, where <code>one outputs data that becomes the input for the other.</code></p> </li> <li> <p>Communicational Cohesion: Two modules form a communication chain, <code>where each operates on information and/or contributes to some output</code>. For example, add a record to the database and generate an email based on that information.</p> </li> <li> <p>Procedural Cohesion: Two modules <code>must execute code in a particular order</code>.</p> </li> <li> <p>Temporal Cohesion: Modules are related based on timing dependencies. For example, many systems have a list of seemingly unrelated things <code>that must be initialized at system startup.</code> These different tasks are temporally cohesive.</p> </li> <li> <p>Logical Cohesion: The data within modules is <code>related logically but not functionally</code>. A common example of this type of cohesion exists in Java in the form of the StringUtils package: <code>a group of static methods that operate on String but are otherwise unrelated.</code></p> </li> <li> <p>Coincidental Cohesion: Elements in a module are not related other than <code>being in the same source file.</code> This represents the most negative form of cohesion.</p> </li> </ol> <p>Cohesion is a <code>less precise metric compared to coupling</code>, often left to the discretion of the architect. Consider this module definition:</p> customer_maintenance.py<pre><code>class CustomerMaintenance:\ndef add_customer():\n...\ndef update_customer():\n...\ndef get_customer():\n...\ndef get_customer_orders():\n...\ndef cancel_customer_orders():\n...\n</code></pre> <p>OR</p> customer_order_maintenance.py<pre><code>class CustomerMaintenance:\ndef add_customer():\n...\ndef update_customer():\n...\ndef get_customer():\n...\nclass OrderMaintenance:\ndef get_customer_orders():\n...\ndef cancel_customer_orders():\n...\n</code></pre> <p>There isn't a one-size-fits-all answer. It depends.</p> <ul> <li> <p>Consider if these are the <code>only two operations for OrderMaintenance</code>; if so, collapsing them into CustomerMaintenance might be appropriate.</p> </li> <li> <p>Is Customer Maintenance expected to grow much larger, encouraging developers to look for opportunities to extract behavior?</p> </li> <li> <p><code>Does OrderMaintenance require so much knowledge of Customer</code> information that separating the two modules would require a high degree of coupling to make it functional?</p> </li> </ul> <p>These questions represent the <code>trade-off analysis</code> at the core of a software architect's role. It involves <code>balancing cohesion and coupling to design an effective and maintainable system</code>.</p>"},{"location":"modularity/measuring/#coupling","title":"Coupling","text":"<p>We have effective tools to analyze coupling in code bases, which rely on <code>graph theory</code>. By considering method calls and returns as a call graph, we can perform mathematical analysis to measure coupling.</p> <p>Two essential metrics are <code>afferent</code> and <code>efferent</code> coupling. <code>Afferent</code> coupling quantifies the number of <code>incoming connections</code> to a code artifact (such as a component, class, or function). <code>Efferent</code> coupling, on the other hand, measures the <code>outgoing connections</code> to other code artifacts. These metrics provide valuable insights into the relationships and dependencies among different parts of the codebase.</p>"},{"location":"modularity/measuring/#abstractness","title":"Abstractness","text":"<p>Abstractness is a metric that <code>calculates the ratio of abstract artifacts</code> (such as abstract classes and interfaces) <code>to concrete artifacts</code> (actual implementations). It provides a measure of <code>how much a codebase is focused on abstract concepts versus concrete implementations</code>.</p> <p>For instance, a codebase with no abstractions and just a large, monolithic function lacks abstractness. On the other hand, a codebase with an excessive number of abstractions can become hard for developers to comprehend and navigate, affecting its overall maintainability.</p>"},{"location":"modularity/measuring/#instability","title":"Instability","text":"<p>The instability metric assesses the volatility of a codebase. A <code>highly unstable codebase is prone to breaking when modified</code>, usually due to excessive coupling. For instance, if a class relies heavily on other classes to delegate tasks, it becomes vulnerable to disruptions when any of the called methods undergo changes. High instability indicates that the codebase is more <code>likely to experience adverse effects from alterations, making it less resilient to changes</code>.</p>"},{"location":"modularity/measuring/#distance-from-the-main","title":"Distance from the Main","text":"<p>The distance metric is a derived metric based on instability and abstractness. It envisions an ideal relationship between these two factors, aiming to find the optimal balance between them.</p>"},{"location":"modularity/measuring/#connascence","title":"Connascence","text":"<p>Two components are connascent if a change in one would require the other to be modified in order to maintain the overall correctness of the system.</p> <p>To now more about:</p> <ol> <li> <p>Connascence: Rules for good software design</p> </li> <li> <p>Connascence</p> </li> </ol>"},{"location":"modularity/measuring/#static-connascence","title":"Static Connascence","text":"<p>Static connascence is a measure of <code>source-code-level coupling</code>. Architects assess the types of static connascence to determine the degree of coupling, whether afferent (incoming) or efferent (outgoing). For example, in a microservices architecture, if <code>two services share the same class definition</code>, such as address, we say they are statically connected to each other. Changing the shared class requires modifications in both services.</p>"},{"location":"modularity/measuring/#dynamic-connascence","title":"Dynamic Connascence","text":"<p>Dynamic connascence is a metric that <code>analyzes calls at runtime</code>, focusing on how different parts of the software interact with each other during execution. It helps architects understand the runtime coupling and dependencies between various components and modules, providing insights into <code>potential performance bottlenecks and areas for optimization</code>.</p>"},{"location":"modularity/measuring/#references","title":"References","text":"<ul> <li>Fundamentals of Software Architecture</li> </ul>"},{"location":"system_design/","title":"System Design","text":"<p><code>System design is a meticulous process encompassing the definition of architecture, components, modules, interfaces, and data to fulfill specific requirements</code>. <code>This entails the translation of user needs into detailed blueprints, providing guidance for the implementation phase</code>. The goal is to create a well-organized and efficient structure that meets the intended purpose. Factors such as scalability, maintainability, and performance are carefully considered throughout this design journey.</p>"},{"location":"system_design/#goal","title":"Goal","text":"<p>The objectives of system design include <code>practicality</code>, <code>accuracy</code>, <code>completeness</code>, <code>efficiency</code>, <code>reliability</code>, <code>optimization</code>, and <code>scalability</code>.</p> <p>Practicality</p> <p>Practicality ensures the system targets the right audience.</p> <p>Accuracy</p> <p>Accuracy means the system should fulfill all <code>functional and non-functional requirements</code>.</p> <p>Completeness</p> <p>Completeness implies the system should meet all user requirements.</p> <p>Efficiency</p> <p>Efficiency requires the system design not to overuse resources or underuse them.</p> <p>Reliability</p> <p>Reliability ensures the system operates in a failure-free environment for a certain period.</p> <p>Optimization</p> <p>Optimization involves optimizing time and space for individual components to work in the system efficiently.</p> <p>Scalability</p> <p>Scalability ensures the system is adaptable with time as per different user needs.</p>"},{"location":"system_design/#references","title":"References","text":"<ol> <li>What is System Design \u2013 Learn System Design</li> </ol>"}]}